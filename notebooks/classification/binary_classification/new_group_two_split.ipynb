{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries for EDA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pingouin as pg\n",
    "from sklearn.preprocessing import StandardScaler \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ageatscreening</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MMSE0m</th>\n",
       "      <th>HipsASMbaseline</th>\n",
       "      <th>HipsContrastbaseline</th>\n",
       "      <th>HipsCorelationbaseline</th>\n",
       "      <th>HipsVariancebaseline</th>\n",
       "      <th>HipsSumAveragebaseline</th>\n",
       "      <th>...</th>\n",
       "      <th>ERCsContrastbaseline</th>\n",
       "      <th>ERCsCorelationbaseline</th>\n",
       "      <th>ERCsVariancebaseline</th>\n",
       "      <th>ERCsSumAveragebaseline</th>\n",
       "      <th>ERCsSumVariancebaseline</th>\n",
       "      <th>ERCsEntropybaseline</th>\n",
       "      <th>ERCsClusterShadebaseline</th>\n",
       "      <th>ERCs_thicknessbaseline</th>\n",
       "      <th>ERCsVolumebaseline</th>\n",
       "      <th>HipposcampusVolumebaseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81.3479</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.27</td>\n",
       "      <td>0.63</td>\n",
       "      <td>218.30</td>\n",
       "      <td>28.37</td>\n",
       "      <td>...</td>\n",
       "      <td>253.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>208.65</td>\n",
       "      <td>23.39</td>\n",
       "      <td>581.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2568.19</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>3047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>67.6904</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>147.64</td>\n",
       "      <td>0.55</td>\n",
       "      <td>173.64</td>\n",
       "      <td>44.72</td>\n",
       "      <td>...</td>\n",
       "      <td>220.88</td>\n",
       "      <td>0.48</td>\n",
       "      <td>215.70</td>\n",
       "      <td>33.74</td>\n",
       "      <td>641.90</td>\n",
       "      <td>3.33</td>\n",
       "      <td>4113.01</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>3449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73.8027</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>199.66</td>\n",
       "      <td>0.55</td>\n",
       "      <td>222.27</td>\n",
       "      <td>41.18</td>\n",
       "      <td>...</td>\n",
       "      <td>220.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>232.18</td>\n",
       "      <td>29.18</td>\n",
       "      <td>708.36</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1388.41</td>\n",
       "      <td>3.18</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>3441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>84.5945</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>184.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>201.55</td>\n",
       "      <td>43.04</td>\n",
       "      <td>...</td>\n",
       "      <td>198.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>220.48</td>\n",
       "      <td>26.68</td>\n",
       "      <td>683.50</td>\n",
       "      <td>2.77</td>\n",
       "      <td>-2506.55</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>2875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>73.9726</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>233.02</td>\n",
       "      <td>0.48</td>\n",
       "      <td>229.88</td>\n",
       "      <td>39.46</td>\n",
       "      <td>...</td>\n",
       "      <td>196.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>210.63</td>\n",
       "      <td>26.60</td>\n",
       "      <td>645.95</td>\n",
       "      <td>2.72</td>\n",
       "      <td>-1164.02</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>2700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RID  Gender  Ageatscreening  Diagnosis  MMSE0m  HipsASMbaseline  \\\n",
       "0    3       0         81.3479          3    20.0              NaN   \n",
       "1    4       0         67.6904          1    27.0             0.06   \n",
       "2    5       0         73.8027          0    29.0             0.10   \n",
       "3    8       1         84.5945          0    28.0             0.08   \n",
       "4   10       1         73.9726          3    24.0             0.11   \n",
       "\n",
       "   HipsContrastbaseline  HipsCorelationbaseline  HipsVariancebaseline  \\\n",
       "0                158.27                    0.63                218.30   \n",
       "1                147.64                    0.55                173.64   \n",
       "2                199.66                    0.55                222.27   \n",
       "3                184.21                    0.53                201.55   \n",
       "4                233.02                    0.48                229.88   \n",
       "\n",
       "   HipsSumAveragebaseline  ...  ERCsContrastbaseline  ERCsCorelationbaseline  \\\n",
       "0                   28.37  ...                253.10                    0.40   \n",
       "1                   44.72  ...                220.88                    0.48   \n",
       "2                   41.18  ...                220.37                    0.54   \n",
       "3                   43.04  ...                198.42                    0.54   \n",
       "4                   39.46  ...                196.55                    0.53   \n",
       "\n",
       "   ERCsVariancebaseline  ERCsSumAveragebaseline  ERCsSumVariancebaseline  \\\n",
       "0                208.65                   23.39                   581.50   \n",
       "1                215.70                   33.74                   641.90   \n",
       "2                232.18                   29.18                   708.36   \n",
       "3                220.48                   26.68                   683.50   \n",
       "4                210.63                   26.60                   645.95   \n",
       "\n",
       "   ERCsEntropybaseline  ERCsClusterShadebaseline  ERCs_thicknessbaseline  \\\n",
       "0                  NaN                  -2568.19                    2.31   \n",
       "1                 3.33                   4113.01                    2.76   \n",
       "2                 2.87                  -1388.41                    3.18   \n",
       "3                 2.77                  -2506.55                    2.68   \n",
       "4                 2.72                  -1164.02                    2.64   \n",
       "\n",
       "   ERCsVolumebaseline  HipposcampusVolumebaseline  \n",
       "0              1176.0                      3047.0  \n",
       "1              1942.0                      3449.0  \n",
       "2              2044.0                      3441.0  \n",
       "3              1959.0                      2875.0  \n",
       "4              1397.0                      2700.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "load_dotenv()\n",
    "dataset_path=os.getenv(\"DATASET_PATH\")\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group two seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_one = dataset[dataset[\"Diagnosis\"] == 0]\n",
    "group_two = dataset[dataset[\"Diagnosis\"] == 3]\n",
    "\n",
    "combined_group_two = pd.concat([group_one, group_two], ignore_index = True)\n",
    "combined_group_two[\"Diagnosis\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ageatscreening</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MMSE0m</th>\n",
       "      <th>HipsASMbaseline</th>\n",
       "      <th>HipsContrastbaseline</th>\n",
       "      <th>HipsCorelationbaseline</th>\n",
       "      <th>HipsVariancebaseline</th>\n",
       "      <th>HipsSumAveragebaseline</th>\n",
       "      <th>...</th>\n",
       "      <th>ERCsContrastbaseline</th>\n",
       "      <th>ERCsCorelationbaseline</th>\n",
       "      <th>ERCsVariancebaseline</th>\n",
       "      <th>ERCsSumAveragebaseline</th>\n",
       "      <th>ERCsSumVariancebaseline</th>\n",
       "      <th>ERCsEntropybaseline</th>\n",
       "      <th>ERCsClusterShadebaseline</th>\n",
       "      <th>ERCs_thicknessbaseline</th>\n",
       "      <th>ERCsVolumebaseline</th>\n",
       "      <th>HipposcampusVolumebaseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73.8027</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>199.66</td>\n",
       "      <td>0.55</td>\n",
       "      <td>222.27</td>\n",
       "      <td>41.18</td>\n",
       "      <td>...</td>\n",
       "      <td>220.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>232.18</td>\n",
       "      <td>29.18</td>\n",
       "      <td>708.36</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1388.41</td>\n",
       "      <td>3.18</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>3441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>84.5945</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>184.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>201.55</td>\n",
       "      <td>43.04</td>\n",
       "      <td>...</td>\n",
       "      <td>198.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>220.48</td>\n",
       "      <td>26.68</td>\n",
       "      <td>683.50</td>\n",
       "      <td>2.77</td>\n",
       "      <td>-2506.55</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>2875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>78.6137</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>188.33</td>\n",
       "      <td>0.49</td>\n",
       "      <td>183.76</td>\n",
       "      <td>39.63</td>\n",
       "      <td>...</td>\n",
       "      <td>241.64</td>\n",
       "      <td>0.44</td>\n",
       "      <td>226.48</td>\n",
       "      <td>35.11</td>\n",
       "      <td>664.29</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8478.33</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>3292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>80.9068</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>161.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>174.53</td>\n",
       "      <td>35.94</td>\n",
       "      <td>...</td>\n",
       "      <td>221.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.12</td>\n",
       "      <td>4287.78</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2188.0</td>\n",
       "      <td>3603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>65.5205</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>166.97</td>\n",
       "      <td>0.58</td>\n",
       "      <td>202.96</td>\n",
       "      <td>38.42</td>\n",
       "      <td>...</td>\n",
       "      <td>228.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>228.72</td>\n",
       "      <td>28.98</td>\n",
       "      <td>686.36</td>\n",
       "      <td>2.90</td>\n",
       "      <td>-1381.99</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>3695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1201</td>\n",
       "      <td>1</td>\n",
       "      <td>75.6411</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>173.84</td>\n",
       "      <td>0.59</td>\n",
       "      <td>215.04</td>\n",
       "      <td>33.84</td>\n",
       "      <td>...</td>\n",
       "      <td>281.15</td>\n",
       "      <td>0.37</td>\n",
       "      <td>222.73</td>\n",
       "      <td>27.94</td>\n",
       "      <td>609.75</td>\n",
       "      <td>2.84</td>\n",
       "      <td>-1924.49</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>2705.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1221</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2712</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>174.02</td>\n",
       "      <td>0.58</td>\n",
       "      <td>211.07</td>\n",
       "      <td>30.56</td>\n",
       "      <td>...</td>\n",
       "      <td>224.78</td>\n",
       "      <td>0.47</td>\n",
       "      <td>205.49</td>\n",
       "      <td>27.36</td>\n",
       "      <td>597.20</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1146.39</td>\n",
       "      <td>2.44</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>2913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1248</td>\n",
       "      <td>1</td>\n",
       "      <td>79.8548</td>\n",
       "      <td>3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>199.31</td>\n",
       "      <td>0.56</td>\n",
       "      <td>229.63</td>\n",
       "      <td>33.13</td>\n",
       "      <td>...</td>\n",
       "      <td>220.41</td>\n",
       "      <td>0.48</td>\n",
       "      <td>214.97</td>\n",
       "      <td>27.16</td>\n",
       "      <td>639.47</td>\n",
       "      <td>2.79</td>\n",
       "      <td>-919.84</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>2273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1253</td>\n",
       "      <td>1</td>\n",
       "      <td>62.7452</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>142.05</td>\n",
       "      <td>0.50</td>\n",
       "      <td>147.12</td>\n",
       "      <td>46.21</td>\n",
       "      <td>...</td>\n",
       "      <td>217.38</td>\n",
       "      <td>0.51</td>\n",
       "      <td>220.55</td>\n",
       "      <td>32.54</td>\n",
       "      <td>664.84</td>\n",
       "      <td>3.09</td>\n",
       "      <td>5289.89</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2321.0</td>\n",
       "      <td>3739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1257</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0849</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>147.66</td>\n",
       "      <td>0.57</td>\n",
       "      <td>180.78</td>\n",
       "      <td>31.82</td>\n",
       "      <td>...</td>\n",
       "      <td>287.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>233.07</td>\n",
       "      <td>29.95</td>\n",
       "      <td>644.68</td>\n",
       "      <td>2.95</td>\n",
       "      <td>-467.36</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>3631.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RID  Gender  Ageatscreening  Diagnosis  MMSE0m  HipsASMbaseline  \\\n",
       "0       5       0         73.8027          0    29.0             0.10   \n",
       "1       8       1         84.5945          0    28.0             0.08   \n",
       "2      14       1         78.6137          0    29.0             0.12   \n",
       "3      15       0         80.9068          0    29.0             0.10   \n",
       "4      16       0         65.5205          0    28.0             0.12   \n",
       "..    ...     ...             ...        ...     ...              ...   \n",
       "319  1201       1         75.6411          3    26.0             0.18   \n",
       "320  1221       0         71.2712          3    21.0             0.22   \n",
       "321  1248       1         79.8548          3    23.0             0.19   \n",
       "322  1253       1         62.7452          3    24.0             0.05   \n",
       "323  1257       0         85.0849          3    20.0             0.15   \n",
       "\n",
       "     HipsContrastbaseline  HipsCorelationbaseline  HipsVariancebaseline  \\\n",
       "0                  199.66                    0.55                222.27   \n",
       "1                  184.21                    0.53                201.55   \n",
       "2                  188.33                    0.49                183.76   \n",
       "3                  161.28                    0.54                174.53   \n",
       "4                  166.97                    0.58                202.96   \n",
       "..                    ...                     ...                   ...   \n",
       "319                173.84                    0.59                215.04   \n",
       "320                174.02                    0.58                211.07   \n",
       "321                199.31                    0.56                229.63   \n",
       "322                142.05                    0.50                147.12   \n",
       "323                147.66                    0.57                180.78   \n",
       "\n",
       "     HipsSumAveragebaseline  ...  ERCsContrastbaseline  \\\n",
       "0                     41.18  ...                220.37   \n",
       "1                     43.04  ...                198.42   \n",
       "2                     39.63  ...                241.64   \n",
       "3                     35.94  ...                221.76   \n",
       "4                     38.42  ...                228.53   \n",
       "..                      ...  ...                   ...   \n",
       "319                   33.84  ...                281.15   \n",
       "320                   30.56  ...                224.78   \n",
       "321                   33.13  ...                220.41   \n",
       "322                   46.21  ...                217.38   \n",
       "323                   31.82  ...                287.61   \n",
       "\n",
       "     ERCsCorelationbaseline  ERCsVariancebaseline  ERCsSumAveragebaseline  \\\n",
       "0                      0.54                232.18                   29.18   \n",
       "1                      0.54                220.48                   26.68   \n",
       "2                      0.44                226.48                   35.11   \n",
       "3                      0.45                   NaN                   30.57   \n",
       "4                      0.50                228.72                   28.98   \n",
       "..                      ...                   ...                     ...   \n",
       "319                    0.37                222.73                   27.94   \n",
       "320                    0.47                205.49                   27.36   \n",
       "321                    0.48                214.97                   27.16   \n",
       "322                    0.51                220.55                   32.54   \n",
       "323                    0.39                233.07                   29.95   \n",
       "\n",
       "     ERCsSumVariancebaseline  ERCsEntropybaseline  ERCsClusterShadebaseline  \\\n",
       "0                     708.36                 2.87                  -1388.41   \n",
       "1                     683.50                 2.77                  -2506.55   \n",
       "2                     664.29                 3.10                   8478.33   \n",
       "3                        NaN                 3.12                   4287.78   \n",
       "4                     686.36                 2.90                  -1381.99   \n",
       "..                       ...                  ...                       ...   \n",
       "319                   609.75                 2.84                  -1924.49   \n",
       "320                   597.20                 2.77                   1146.39   \n",
       "321                   639.47                 2.79                   -919.84   \n",
       "322                   664.84                 3.09                   5289.89   \n",
       "323                   644.68                 2.95                   -467.36   \n",
       "\n",
       "     ERCs_thicknessbaseline  ERCsVolumebaseline  HipposcampusVolumebaseline  \n",
       "0                      3.18              2044.0                      3441.0  \n",
       "1                      2.68              1959.0                      2875.0  \n",
       "2                      3.01              1809.0                      3292.0  \n",
       "3                      2.90              2188.0                      3603.0  \n",
       "4                      2.73              1829.0                      3695.0  \n",
       "..                      ...                 ...                         ...  \n",
       "319                    1.94              1112.0                      2705.0  \n",
       "320                    2.44              1526.0                      2913.0  \n",
       "321                    1.99              1215.0                      2273.0  \n",
       "322                    3.27              2321.0                      3739.0  \n",
       "323                    2.45              1819.0                      3631.0  \n",
       "\n",
       "[324 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_group_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_group_two.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RID                            0\n",
       "Gender                         0\n",
       "Ageatscreening                 0\n",
       "Diagnosis                      0\n",
       "MMSE0m                         1\n",
       "HipsASMbaseline               20\n",
       "HipsContrastbaseline          10\n",
       "HipsCorelationbaseline        13\n",
       "HipsVariancebaseline           5\n",
       "HipsSumAveragebaseline         1\n",
       "HipsSumVariancebaseline        6\n",
       "HipsEntropybaseline           20\n",
       "HipsClusterShadebaseline      12\n",
       "ERCsASMbaseline                2\n",
       "ERCsContrastbaseline          11\n",
       "ERCsCorelationbaseline        14\n",
       "ERCsVariancebaseline           8\n",
       "ERCsSumAveragebaseline         9\n",
       "ERCsSumVariancebaseline        5\n",
       "ERCsEntropybaseline            7\n",
       "ERCsClusterShadebaseline      19\n",
       "ERCs_thicknessbaseline        29\n",
       "ERCsVolumebaseline             9\n",
       "HipposcampusVolumebaseline    16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_group_two.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 24)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_group_two_drop = combined_group_two.dropna()\n",
    "combined_group_two_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156, 23), (68, 23))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "\n",
    "# let's separate into training and testing set\n",
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
    "    combined_group_two_drop.drop(\"Diagnosis\", axis=1),  \n",
    "    combined_group_two_drop[\"Diagnosis\"],  \n",
    "    test_size=0.3,  \n",
    "    random_state=0,  \n",
    ")\n",
    "\n",
    "X_train_t.shape, X_test_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "0    130\n",
       "3     94\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_split_one = combined_group_two_drop[\"Diagnosis\"]\n",
    "y_split_one.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Diagnosis'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_split_one.value_counts(normalize=True).plot(kind=\"bar\",\n",
    "                                                color = \"#5e76fe\",\n",
    "                                                width = 0.4,\n",
    "                                                edgecolor = \"black\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((226, 23), (98, 23))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "\n",
    "# let's separate into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    combined_group_two.drop(\"Diagnosis\", axis=1),  \n",
    "    combined_group_two[\"Diagnosis\"],  \n",
    "    test_size=0.3,  \n",
    "    random_state=0,  \n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"imputer\", MeanMedianImputer(\n",
    "        imputation_method=\"mean\", \n",
    "        variables=[\n",
    "            'MMSE0m', 'HipsASMbaseline', 'HipsContrastbaseline',\n",
    "            'HipsCorelationbaseline', 'HipsVariancebaseline',\n",
    "            'HipsSumAveragebaseline', 'HipsSumVariancebaseline',\n",
    "            'HipsEntropybaseline', 'HipsClusterShadebaseline', \n",
    "            'ERCsASMbaseline', 'ERCsContrastbaseline', \n",
    "            'ERCsCorelationbaseline', 'ERCsVariancebaseline', \n",
    "            'ERCsSumAveragebaseline', 'ERCsSumVariancebaseline',\n",
    "            'ERCsEntropybaseline', 'ERCsClusterShadebaseline', \n",
    "            'ERCs_thicknessbaseline', 'ERCsVolumebaseline', \n",
    "            'HipposcampusVolumebaseline'\n",
    "        ]\n",
    "    )),\n",
    "    (\"scaler\", StandardScaler().set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train)\n",
    "\n",
    "# let's transform the data with the pipeline\n",
    "X_train_scaled = pipe.transform(X_train)\n",
    "X_test_scaled = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score, balanced_accuracy_score, make_scorer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def run_model(model, classifier_name, X_train, y_train):\n",
    "        \n",
    "        kf = StratifiedKFold(n_splits=5,\n",
    "                             shuffle=True,\n",
    "                             random_state=42,\n",
    "        )\n",
    "        \n",
    "        metrics = {\"accuracy\": make_scorer(accuracy_score),\n",
    "                   \"balanced_accuracy\": make_scorer(balanced_accuracy_score),  \n",
    "                   \"precision\": make_scorer(precision_score, average=\"weighted\"), \n",
    "                   \"recall\": make_scorer(recall_score, average=\"weighted\"), \n",
    "                   \"f1_weighted\": make_scorer(f1_score, average=\"weighted\"),\n",
    "                   \"roc_auc_ovr_weighted\": make_scorer(roc_auc_score, \n",
    "                                                       average=\"weighted\", \n",
    "                                                       multi_class=\"ovr\", \n",
    "                                                       response_method=\"predict_proba\",),\n",
    "        }\n",
    "        \n",
    "        cross_val_results = cross_validate(model,\n",
    "                                           X_train,\n",
    "                                           y_train,\n",
    "                                           cv=kf,\n",
    "                                           scoring=metrics,\n",
    "                                           return_train_score=True,\n",
    "        )\n",
    "                \n",
    "        metric_names = list(metrics.keys())\n",
    "        mean_train = [round(np.mean(cross_val_results[f\"train_{metric}\"]), 3) for metric in metric_names]\n",
    "        std_train = [round(np.std(cross_val_results[f\"train_{metric}\"]), 3) for metric in metric_names]\n",
    "        mean_test = [round(np.mean(cross_val_results[f\"test_{metric}\"]), 3) for metric in metric_names]\n",
    "        std_test = [round(np.std(cross_val_results[f\"test_{metric}\"]), 3) for metric in metric_names]\n",
    "        time = round(np.mean(cross_val_results[f\"fit_time\"]), 3)\n",
    "                \n",
    "        cv_metrics_df = pd.DataFrame({\n",
    "                \"Classifier\": classifier_name,\n",
    "                \"Fit Time\": time,\n",
    "                \"Metric\": metric_names,\n",
    "                \"Mean Train\": mean_train,\n",
    "                \"Std Train\": std_train,\n",
    "                \"Mean Test\": mean_test,\n",
    "                \"Std Test\": std_test,\n",
    "        })\n",
    "        \n",
    "        fit_model = model.fit(X_train, y_train)\n",
    "        \n",
    "        return fit_model, cv_metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42, class_weight=\"balanced\",\n",
    "        )\n",
    "lg = LogisticRegression(multi_class = \"auto\", solver = \"lbfgs\", max_iter = 1000, random_state = 42)\n",
    "\n",
    "svm = SVC(kernel ='rbf', decision_function_shape ='ovr', probability = True, random_state = 42)\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion ='gini', max_depth = 5, min_samples_split = 10,\n",
    "                                                  min_samples_leaf = 5, max_features = 'sqrt', random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_rf, metrics_rf = run_model(rf, \"Random Forest\", X_train, y_train)\n",
    "model_dt, metrics_dt = run_model(dt, \"Decision Tree\", X_train, y_train)\n",
    "model_lg, metrics_lg = run_model(svm, \"Logistic Regression\", X_train_scaled, y_train)\n",
    "model_svm, metrics_svm = run_model(lg, \"Support Vector Machine\", X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean Train</th>\n",
       "      <th>Std Train</th>\n",
       "      <th>Mean Test</th>\n",
       "      <th>Std Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th>Fit Time</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Random Forest</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.362</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Decision Tree</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.005</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.921</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Logistic Regression</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.014</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Support Vector Machine</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.011</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Mean Train  Std Train  \\\n",
       "Classifier             Fit Time Metric                                        \n",
       "Random Forest          0.362    accuracy                   1.000      0.000   \n",
       "                                balanced_accuracy          1.000      0.000   \n",
       "                                precision                  1.000      0.000   \n",
       "                                recall                     1.000      0.000   \n",
       "                                f1_weighted                1.000      0.000   \n",
       "                                roc_auc_ovr_weighted       1.000      0.000   \n",
       "Decision Tree          0.005    accuracy                   0.921      0.024   \n",
       "                                balanced_accuracy          0.921      0.026   \n",
       "                                precision                  0.926      0.024   \n",
       "                                recall                     0.921      0.024   \n",
       "                                f1_weighted                0.921      0.024   \n",
       "                                roc_auc_ovr_weighted       0.977      0.014   \n",
       "Logistic Regression    0.014    accuracy                   0.982      0.004   \n",
       "                                balanced_accuracy          0.979      0.005   \n",
       "                                precision                  0.983      0.004   \n",
       "                                recall                     0.982      0.004   \n",
       "                                f1_weighted                0.982      0.004   \n",
       "                                roc_auc_ovr_weighted       0.999      0.000   \n",
       "Support Vector Machine 0.011    accuracy                   0.987      0.004   \n",
       "                                balanced_accuracy          0.985      0.004   \n",
       "                                precision                  0.987      0.004   \n",
       "                                recall                     0.987      0.004   \n",
       "                                f1_weighted                0.987      0.004   \n",
       "                                roc_auc_ovr_weighted       0.999      0.000   \n",
       "\n",
       "                                                      Mean Test  Std Test  \n",
       "Classifier             Fit Time Metric                                     \n",
       "Random Forest          0.362    accuracy                  0.960     0.026  \n",
       "                                balanced_accuracy         0.958     0.028  \n",
       "                                precision                 0.961     0.026  \n",
       "                                recall                    0.960     0.026  \n",
       "                                f1_weighted               0.960     0.026  \n",
       "                                roc_auc_ovr_weighted      0.989     0.014  \n",
       "Decision Tree          0.005    accuracy                  0.823     0.055  \n",
       "                                balanced_accuracy         0.819     0.056  \n",
       "                                precision                 0.824     0.053  \n",
       "                                recall                    0.823     0.055  \n",
       "                                f1_weighted               0.823     0.055  \n",
       "                                roc_auc_ovr_weighted      0.855     0.037  \n",
       "Logistic Regression    0.014    accuracy                  0.956     0.014  \n",
       "                                balanced_accuracy         0.951     0.014  \n",
       "                                precision                 0.957     0.014  \n",
       "                                recall                    0.956     0.014  \n",
       "                                f1_weighted               0.956     0.014  \n",
       "                                roc_auc_ovr_weighted      0.986     0.010  \n",
       "Support Vector Machine 0.011    accuracy                  0.978     0.014  \n",
       "                                balanced_accuracy         0.977     0.015  \n",
       "                                precision                 0.978     0.014  \n",
       "                                recall                    0.978     0.014  \n",
       "                                f1_weighted               0.978     0.014  \n",
       "                                roc_auc_ovr_weighted      0.996     0.004  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df = pd.concat([metrics_rf, metrics_dt, metrics_lg, metrics_svm])\n",
    "validation_df_report = validation_df.set_index([\"Classifier\", \"Fit Time\", \"Metric\"])\n",
    "validation_df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def model_eval(model, classifier_name, X_train, X_test, y_train, y_test):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Ensure that y_train and y_test are 1D arrays\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "    \n",
    "    # Get predicted probabilities for ROC AUC\n",
    "    pred_train_proba = model.predict_proba(X_train)\n",
    "    pred_test_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # Get predicted classes for other metrics\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    # For binary classification, use the probability of the positive class only:\n",
    "    roc_auc_train = roc_auc_score(y_train, pred_train_proba[:, 1])\n",
    "    roc_auc_test = roc_auc_score(y_test, pred_test_proba[:, 1])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics_train = {\n",
    "        \"accuracy\": round(accuracy_score(y_train, pred_train), 3),\n",
    "        \"balanced_accuracy\": round(balanced_accuracy_score(y_train, pred_train), 3),\n",
    "        \"precision\": round(precision_score(y_train, pred_train, average=\"weighted\"), 3),\n",
    "        \"recall\": round(recall_score(y_train, pred_train, average=\"weighted\"), 3),\n",
    "        \"f1_weighted\": round(f1_score(y_train, pred_train, average=\"weighted\"), 3),\n",
    "        \"roc_auc\": round(roc_auc_train, 3),\n",
    "    }\n",
    "    \n",
    "    metrics_test = {\n",
    "        \"accuracy\": round(accuracy_score(y_test, pred_test), 3),\n",
    "        \"balanced_accuracy\": round(balanced_accuracy_score(y_test, pred_test), 3),\n",
    "        \"precision\": round(precision_score(y_test, pred_test, average=\"weighted\"), 3),\n",
    "        \"recall\": round(recall_score(y_test, pred_test, average=\"weighted\"), 3),\n",
    "        \"f1_weighted\": round(f1_score(y_test, pred_test, average=\"weighted\"), 3),\n",
    "        \"roc_auc\": round(roc_auc_test, 3),\n",
    "    }\n",
    "            \n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Create the DataFrame without additional rounding issues\n",
    "    pred_metrics_df = pd.DataFrame({\n",
    "        \"Classifier\": classifier_name,\n",
    "        \"Classification Time\": round(elapsed_time, 3),\n",
    "        \"Metric\": list(metrics_train.keys()),\n",
    "        \"Train data\": list(metrics_train.values()),\n",
    "        \"Test data\": list(metrics_test.values()),\n",
    "    })\n",
    "    \n",
    "    return pred_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = model_eval(model_rf,\"Random Forest\", X_train, X_test, y_train, y_test)\n",
    "pred_dt = model_eval(model_dt,\"Decision Tree\", X_train, X_test, y_train, y_test)\n",
    "pred_lg = model_eval(model_lg,\"Logistic Regression\", X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "pred_svm = model_eval(model_svm,\"Support Vector Machine\", X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Train data</th>\n",
       "      <th>Test data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th>Classification Time</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Random Forest</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.112</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Decision Tree</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.038</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.900</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.899</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.964</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Logistic Regression</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.039</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Support Vector Machine</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.033</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Train data  \\\n",
       "Classifier             Classification Time Metric                          \n",
       "Random Forest          0.112               accuracy                1.000   \n",
       "                                           balanced_accuracy       1.000   \n",
       "                                           precision               1.000   \n",
       "                                           recall                  1.000   \n",
       "                                           f1_weighted             1.000   \n",
       "                                           roc_auc                 1.000   \n",
       "Decision Tree          0.038               accuracy                0.898   \n",
       "                                           balanced_accuracy       0.899   \n",
       "                                           precision               0.900   \n",
       "                                           recall                  0.898   \n",
       "                                           f1_weighted             0.899   \n",
       "                                           roc_auc                 0.964   \n",
       "Logistic Regression    0.039               accuracy                0.982   \n",
       "                                           balanced_accuracy       0.979   \n",
       "                                           precision               0.983   \n",
       "                                           recall                  0.982   \n",
       "                                           f1_weighted             0.982   \n",
       "                                           roc_auc                 0.999   \n",
       "Support Vector Machine 0.033               accuracy                0.982   \n",
       "                                           balanced_accuracy       0.982   \n",
       "                                           precision               0.982   \n",
       "                                           recall                  0.982   \n",
       "                                           f1_weighted             0.982   \n",
       "                                           roc_auc                 0.999   \n",
       "\n",
       "                                                              Test data  \n",
       "Classifier             Classification Time Metric                        \n",
       "Random Forest          0.112               accuracy               0.949  \n",
       "                                           balanced_accuracy      0.947  \n",
       "                                           precision              0.950  \n",
       "                                           recall                 0.949  \n",
       "                                           f1_weighted            0.949  \n",
       "                                           roc_auc                0.992  \n",
       "Decision Tree          0.038               accuracy               0.765  \n",
       "                                           balanced_accuracy      0.772  \n",
       "                                           precision              0.788  \n",
       "                                           recall                 0.765  \n",
       "                                           f1_weighted            0.770  \n",
       "                                           roc_auc                0.780  \n",
       "Logistic Regression    0.039               accuracy               0.969  \n",
       "                                           balanced_accuracy      0.963  \n",
       "                                           precision              0.969  \n",
       "                                           recall                 0.969  \n",
       "                                           f1_weighted            0.969  \n",
       "                                           roc_auc                0.994  \n",
       "Support Vector Machine 0.033               accuracy               0.959  \n",
       "                                           balanced_accuracy      0.955  \n",
       "                                           precision              0.959  \n",
       "                                           recall                 0.959  \n",
       "                                           f1_weighted            0.959  \n",
       "                                           roc_auc                0.993  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.concat([pred_rf, pred_dt, pred_lg, pred_svm])\n",
    "prediction_df_report = prediction_df.set_index([\"Classifier\", \"Classification Time\", \"Metric\"])\n",
    "prediction_df_report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
