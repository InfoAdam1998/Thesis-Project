{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries for EDA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pingouin as pg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ageatscreening</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MMSE0m</th>\n",
       "      <th>HipsASMbaseline</th>\n",
       "      <th>HipsContrastbaseline</th>\n",
       "      <th>HipsCorelationbaseline</th>\n",
       "      <th>HipsVariancebaseline</th>\n",
       "      <th>HipsSumAveragebaseline</th>\n",
       "      <th>...</th>\n",
       "      <th>ERCsContrastbaseline</th>\n",
       "      <th>ERCsCorelationbaseline</th>\n",
       "      <th>ERCsVariancebaseline</th>\n",
       "      <th>ERCsSumAveragebaseline</th>\n",
       "      <th>ERCsSumVariancebaseline</th>\n",
       "      <th>ERCsEntropybaseline</th>\n",
       "      <th>ERCsClusterShadebaseline</th>\n",
       "      <th>ERCs_thicknessbaseline</th>\n",
       "      <th>ERCsVolumebaseline</th>\n",
       "      <th>HipposcampusVolumebaseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81.3479</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.27</td>\n",
       "      <td>0.63</td>\n",
       "      <td>218.30</td>\n",
       "      <td>28.37</td>\n",
       "      <td>...</td>\n",
       "      <td>253.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>208.65</td>\n",
       "      <td>23.39</td>\n",
       "      <td>581.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2568.19</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>3047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>67.6904</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>147.64</td>\n",
       "      <td>0.55</td>\n",
       "      <td>173.64</td>\n",
       "      <td>44.72</td>\n",
       "      <td>...</td>\n",
       "      <td>220.88</td>\n",
       "      <td>0.48</td>\n",
       "      <td>215.70</td>\n",
       "      <td>33.74</td>\n",
       "      <td>641.90</td>\n",
       "      <td>3.33</td>\n",
       "      <td>4113.01</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>3449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73.8027</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>199.66</td>\n",
       "      <td>0.55</td>\n",
       "      <td>222.27</td>\n",
       "      <td>41.18</td>\n",
       "      <td>...</td>\n",
       "      <td>220.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>232.18</td>\n",
       "      <td>29.18</td>\n",
       "      <td>708.36</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1388.41</td>\n",
       "      <td>3.18</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>3441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>84.5945</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>184.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>201.55</td>\n",
       "      <td>43.04</td>\n",
       "      <td>...</td>\n",
       "      <td>198.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>220.48</td>\n",
       "      <td>26.68</td>\n",
       "      <td>683.50</td>\n",
       "      <td>2.77</td>\n",
       "      <td>-2506.55</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>2875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>73.9726</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>233.02</td>\n",
       "      <td>0.48</td>\n",
       "      <td>229.88</td>\n",
       "      <td>39.46</td>\n",
       "      <td>...</td>\n",
       "      <td>196.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>210.63</td>\n",
       "      <td>26.60</td>\n",
       "      <td>645.95</td>\n",
       "      <td>2.72</td>\n",
       "      <td>-1164.02</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>2700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RID  Gender  Ageatscreening  Diagnosis  MMSE0m  HipsASMbaseline  \\\n",
       "0    3       0         81.3479          3    20.0              NaN   \n",
       "1    4       0         67.6904          1    27.0             0.06   \n",
       "2    5       0         73.8027          0    29.0             0.10   \n",
       "3    8       1         84.5945          0    28.0             0.08   \n",
       "4   10       1         73.9726          3    24.0             0.11   \n",
       "\n",
       "   HipsContrastbaseline  HipsCorelationbaseline  HipsVariancebaseline  \\\n",
       "0                158.27                    0.63                218.30   \n",
       "1                147.64                    0.55                173.64   \n",
       "2                199.66                    0.55                222.27   \n",
       "3                184.21                    0.53                201.55   \n",
       "4                233.02                    0.48                229.88   \n",
       "\n",
       "   HipsSumAveragebaseline  ...  ERCsContrastbaseline  ERCsCorelationbaseline  \\\n",
       "0                   28.37  ...                253.10                    0.40   \n",
       "1                   44.72  ...                220.88                    0.48   \n",
       "2                   41.18  ...                220.37                    0.54   \n",
       "3                   43.04  ...                198.42                    0.54   \n",
       "4                   39.46  ...                196.55                    0.53   \n",
       "\n",
       "   ERCsVariancebaseline  ERCsSumAveragebaseline  ERCsSumVariancebaseline  \\\n",
       "0                208.65                   23.39                   581.50   \n",
       "1                215.70                   33.74                   641.90   \n",
       "2                232.18                   29.18                   708.36   \n",
       "3                220.48                   26.68                   683.50   \n",
       "4                210.63                   26.60                   645.95   \n",
       "\n",
       "   ERCsEntropybaseline  ERCsClusterShadebaseline  ERCs_thicknessbaseline  \\\n",
       "0                  NaN                  -2568.19                    2.31   \n",
       "1                 3.33                   4113.01                    2.76   \n",
       "2                 2.87                  -1388.41                    3.18   \n",
       "3                 2.77                  -2506.55                    2.68   \n",
       "4                 2.72                  -1164.02                    2.64   \n",
       "\n",
       "   ERCsVolumebaseline  HipposcampusVolumebaseline  \n",
       "0              1176.0                      3047.0  \n",
       "1              1942.0                      3449.0  \n",
       "2              2044.0                      3441.0  \n",
       "3              1959.0                      2875.0  \n",
       "4              1397.0                      2700.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "load_dotenv()\n",
    "dataset_path=os.getenv(\"DATASET_PATH\")\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group one seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_one = dataset[dataset[\"Diagnosis\"] == 0]\n",
    "group_two = dataset[dataset[\"Diagnosis\"] == 3]\n",
    "\n",
    "combined_group_one = pd.concat([group_one, group_two], ignore_index = True)\n",
    "combined_group_one[\"Diagnosis\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ageatscreening</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MMSE0m</th>\n",
       "      <th>HipsASMbaseline</th>\n",
       "      <th>HipsContrastbaseline</th>\n",
       "      <th>HipsCorelationbaseline</th>\n",
       "      <th>HipsVariancebaseline</th>\n",
       "      <th>HipsSumAveragebaseline</th>\n",
       "      <th>...</th>\n",
       "      <th>ERCsContrastbaseline</th>\n",
       "      <th>ERCsCorelationbaseline</th>\n",
       "      <th>ERCsVariancebaseline</th>\n",
       "      <th>ERCsSumAveragebaseline</th>\n",
       "      <th>ERCsSumVariancebaseline</th>\n",
       "      <th>ERCsEntropybaseline</th>\n",
       "      <th>ERCsClusterShadebaseline</th>\n",
       "      <th>ERCs_thicknessbaseline</th>\n",
       "      <th>ERCsVolumebaseline</th>\n",
       "      <th>HipposcampusVolumebaseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73.8027</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>199.66</td>\n",
       "      <td>0.55</td>\n",
       "      <td>222.27</td>\n",
       "      <td>41.18</td>\n",
       "      <td>...</td>\n",
       "      <td>220.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>232.18</td>\n",
       "      <td>29.18</td>\n",
       "      <td>708.36</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1388.41</td>\n",
       "      <td>3.18</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>3441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>84.5945</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>184.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>201.55</td>\n",
       "      <td>43.04</td>\n",
       "      <td>...</td>\n",
       "      <td>198.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>220.48</td>\n",
       "      <td>26.68</td>\n",
       "      <td>683.50</td>\n",
       "      <td>2.77</td>\n",
       "      <td>-2506.55</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>2875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>78.6137</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>188.33</td>\n",
       "      <td>0.49</td>\n",
       "      <td>183.76</td>\n",
       "      <td>39.63</td>\n",
       "      <td>...</td>\n",
       "      <td>241.64</td>\n",
       "      <td>0.44</td>\n",
       "      <td>226.48</td>\n",
       "      <td>35.11</td>\n",
       "      <td>664.29</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8478.33</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>3292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>80.9068</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>161.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>174.53</td>\n",
       "      <td>35.94</td>\n",
       "      <td>...</td>\n",
       "      <td>221.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.12</td>\n",
       "      <td>4287.78</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2188.0</td>\n",
       "      <td>3603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>65.5205</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>166.97</td>\n",
       "      <td>0.58</td>\n",
       "      <td>202.96</td>\n",
       "      <td>38.42</td>\n",
       "      <td>...</td>\n",
       "      <td>228.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>228.72</td>\n",
       "      <td>28.98</td>\n",
       "      <td>686.36</td>\n",
       "      <td>2.90</td>\n",
       "      <td>-1381.99</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>3695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>1201</td>\n",
       "      <td>1</td>\n",
       "      <td>75.6411</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>173.84</td>\n",
       "      <td>0.59</td>\n",
       "      <td>215.04</td>\n",
       "      <td>33.84</td>\n",
       "      <td>...</td>\n",
       "      <td>281.15</td>\n",
       "      <td>0.37</td>\n",
       "      <td>222.73</td>\n",
       "      <td>27.94</td>\n",
       "      <td>609.75</td>\n",
       "      <td>2.84</td>\n",
       "      <td>-1924.49</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1112.0</td>\n",
       "      <td>2705.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1221</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2712</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>174.02</td>\n",
       "      <td>0.58</td>\n",
       "      <td>211.07</td>\n",
       "      <td>30.56</td>\n",
       "      <td>...</td>\n",
       "      <td>224.78</td>\n",
       "      <td>0.47</td>\n",
       "      <td>205.49</td>\n",
       "      <td>27.36</td>\n",
       "      <td>597.20</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1146.39</td>\n",
       "      <td>2.44</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>2913.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1248</td>\n",
       "      <td>1</td>\n",
       "      <td>79.8548</td>\n",
       "      <td>3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>199.31</td>\n",
       "      <td>0.56</td>\n",
       "      <td>229.63</td>\n",
       "      <td>33.13</td>\n",
       "      <td>...</td>\n",
       "      <td>220.41</td>\n",
       "      <td>0.48</td>\n",
       "      <td>214.97</td>\n",
       "      <td>27.16</td>\n",
       "      <td>639.47</td>\n",
       "      <td>2.79</td>\n",
       "      <td>-919.84</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1215.0</td>\n",
       "      <td>2273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1253</td>\n",
       "      <td>1</td>\n",
       "      <td>62.7452</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>142.05</td>\n",
       "      <td>0.50</td>\n",
       "      <td>147.12</td>\n",
       "      <td>46.21</td>\n",
       "      <td>...</td>\n",
       "      <td>217.38</td>\n",
       "      <td>0.51</td>\n",
       "      <td>220.55</td>\n",
       "      <td>32.54</td>\n",
       "      <td>664.84</td>\n",
       "      <td>3.09</td>\n",
       "      <td>5289.89</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2321.0</td>\n",
       "      <td>3739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1257</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0849</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>147.66</td>\n",
       "      <td>0.57</td>\n",
       "      <td>180.78</td>\n",
       "      <td>31.82</td>\n",
       "      <td>...</td>\n",
       "      <td>287.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>233.07</td>\n",
       "      <td>29.95</td>\n",
       "      <td>644.68</td>\n",
       "      <td>2.95</td>\n",
       "      <td>-467.36</td>\n",
       "      <td>2.45</td>\n",
       "      <td>1819.0</td>\n",
       "      <td>3631.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>324 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RID  Gender  Ageatscreening  Diagnosis  MMSE0m  HipsASMbaseline  \\\n",
       "0       5       0         73.8027          0    29.0             0.10   \n",
       "1       8       1         84.5945          0    28.0             0.08   \n",
       "2      14       1         78.6137          0    29.0             0.12   \n",
       "3      15       0         80.9068          0    29.0             0.10   \n",
       "4      16       0         65.5205          0    28.0             0.12   \n",
       "..    ...     ...             ...        ...     ...              ...   \n",
       "319  1201       1         75.6411          3    26.0             0.18   \n",
       "320  1221       0         71.2712          3    21.0             0.22   \n",
       "321  1248       1         79.8548          3    23.0             0.19   \n",
       "322  1253       1         62.7452          3    24.0             0.05   \n",
       "323  1257       0         85.0849          3    20.0             0.15   \n",
       "\n",
       "     HipsContrastbaseline  HipsCorelationbaseline  HipsVariancebaseline  \\\n",
       "0                  199.66                    0.55                222.27   \n",
       "1                  184.21                    0.53                201.55   \n",
       "2                  188.33                    0.49                183.76   \n",
       "3                  161.28                    0.54                174.53   \n",
       "4                  166.97                    0.58                202.96   \n",
       "..                    ...                     ...                   ...   \n",
       "319                173.84                    0.59                215.04   \n",
       "320                174.02                    0.58                211.07   \n",
       "321                199.31                    0.56                229.63   \n",
       "322                142.05                    0.50                147.12   \n",
       "323                147.66                    0.57                180.78   \n",
       "\n",
       "     HipsSumAveragebaseline  ...  ERCsContrastbaseline  \\\n",
       "0                     41.18  ...                220.37   \n",
       "1                     43.04  ...                198.42   \n",
       "2                     39.63  ...                241.64   \n",
       "3                     35.94  ...                221.76   \n",
       "4                     38.42  ...                228.53   \n",
       "..                      ...  ...                   ...   \n",
       "319                   33.84  ...                281.15   \n",
       "320                   30.56  ...                224.78   \n",
       "321                   33.13  ...                220.41   \n",
       "322                   46.21  ...                217.38   \n",
       "323                   31.82  ...                287.61   \n",
       "\n",
       "     ERCsCorelationbaseline  ERCsVariancebaseline  ERCsSumAveragebaseline  \\\n",
       "0                      0.54                232.18                   29.18   \n",
       "1                      0.54                220.48                   26.68   \n",
       "2                      0.44                226.48                   35.11   \n",
       "3                      0.45                   NaN                   30.57   \n",
       "4                      0.50                228.72                   28.98   \n",
       "..                      ...                   ...                     ...   \n",
       "319                    0.37                222.73                   27.94   \n",
       "320                    0.47                205.49                   27.36   \n",
       "321                    0.48                214.97                   27.16   \n",
       "322                    0.51                220.55                   32.54   \n",
       "323                    0.39                233.07                   29.95   \n",
       "\n",
       "     ERCsSumVariancebaseline  ERCsEntropybaseline  ERCsClusterShadebaseline  \\\n",
       "0                     708.36                 2.87                  -1388.41   \n",
       "1                     683.50                 2.77                  -2506.55   \n",
       "2                     664.29                 3.10                   8478.33   \n",
       "3                        NaN                 3.12                   4287.78   \n",
       "4                     686.36                 2.90                  -1381.99   \n",
       "..                       ...                  ...                       ...   \n",
       "319                   609.75                 2.84                  -1924.49   \n",
       "320                   597.20                 2.77                   1146.39   \n",
       "321                   639.47                 2.79                   -919.84   \n",
       "322                   664.84                 3.09                   5289.89   \n",
       "323                   644.68                 2.95                   -467.36   \n",
       "\n",
       "     ERCs_thicknessbaseline  ERCsVolumebaseline  HipposcampusVolumebaseline  \n",
       "0                      3.18              2044.0                      3441.0  \n",
       "1                      2.68              1959.0                      2875.0  \n",
       "2                      3.01              1809.0                      3292.0  \n",
       "3                      2.90              2188.0                      3603.0  \n",
       "4                      2.73              1829.0                      3695.0  \n",
       "..                      ...                 ...                         ...  \n",
       "319                    1.94              1112.0                      2705.0  \n",
       "320                    2.44              1526.0                      2913.0  \n",
       "321                    1.99              1215.0                      2273.0  \n",
       "322                    3.27              2321.0                      3739.0  \n",
       "323                    2.45              1819.0                      3631.0  \n",
       "\n",
       "[324 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_group_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((226, 23), (98, 23))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# let's separate into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    combined_group_one.drop(\"Diagnosis\", axis=1),  \n",
    "    combined_group_one[\"Diagnosis\"],  \n",
    "    test_size=0.3,  \n",
    "    random_state=0,  \n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler()\n",
    "sc.fit_transform(X_train)\n",
    "\n",
    "# let's transform the data with the pipeline\n",
    "X_train_scaled = sc.transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score, balanced_accuracy_score, make_scorer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def run_model(model, classifier_name, X_train, y_train):\n",
    "        \n",
    "        kf = StratifiedKFold(n_splits=5,\n",
    "                             shuffle=True,\n",
    "                             random_state=42,\n",
    "        )\n",
    "        \n",
    "        metrics = {\"accuracy\": make_scorer(accuracy_score),\n",
    "                   \"balanced_accuracy\": make_scorer(balanced_accuracy_score),  \n",
    "                   \"precision\": make_scorer(precision_score, average=\"weighted\"), \n",
    "                   \"recall\": make_scorer(recall_score, average=\"weighted\"), \n",
    "                   \"f1_weighted\": make_scorer(f1_score, average=\"weighted\"),\n",
    "                   \"roc_auc_ovr_weighted\": make_scorer(roc_auc_score, \n",
    "                                                       average=\"weighted\", \n",
    "                                                       multi_class=\"ovr\", \n",
    "                                                       response_method=\"predict_proba\",),\n",
    "        }\n",
    "        \n",
    "        cross_val_results = cross_validate(model,\n",
    "                                           X_train,\n",
    "                                           y_train,\n",
    "                                           cv=kf,\n",
    "                                           scoring=metrics,\n",
    "                                           return_train_score=True,\n",
    "        )\n",
    "                \n",
    "        metric_names = list(metrics.keys())\n",
    "        mean_train = [round(np.mean(cross_val_results[f\"train_{metric}\"]), 3) for metric in metric_names]\n",
    "        std_train = [round(np.std(cross_val_results[f\"train_{metric}\"]), 3) for metric in metric_names]\n",
    "        mean_test = [round(np.mean(cross_val_results[f\"test_{metric}\"]), 3) for metric in metric_names]\n",
    "        std_test = [round(np.std(cross_val_results[f\"test_{metric}\"]), 3) for metric in metric_names]\n",
    "        time = round(np.mean(cross_val_results[f\"fit_time\"]), 3)\n",
    "                \n",
    "        cv_metrics_df = pd.DataFrame({\n",
    "                \"Classifier\": classifier_name,\n",
    "                \"Fit Time\": time,\n",
    "                \"Metric\": metric_names,\n",
    "                \"Mean Train\": mean_train,\n",
    "                \"Std Train\": std_train,\n",
    "                \"Mean Test\": mean_test,\n",
    "                \"Std Test\": std_test,\n",
    "        })\n",
    "        \n",
    "        fit_model = model.fit(X_train, y_train)\n",
    "        \n",
    "        return fit_model, cv_metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42, class_weight=\"balanced\",\n",
    "        )\n",
    "lg = LogisticRegression(multi_class = \"auto\", solver = \"lbfgs\", max_iter = 1000, random_state = 42)\n",
    "\n",
    "svm = SVC(kernel ='rbf', decision_function_shape ='ovr', probability = True, random_state = 42)\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion ='gini', max_depth = 5, min_samples_split = 10,\n",
    "                                                  min_samples_leaf = 5, max_features = 'sqrt', random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1064, in check_array\n    _assert_all_finite(\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_rf, metrics_rf \u001b[38;5;241m=\u001b[39m run_model(rf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train, y_train)\n\u001b[1;32m----> 2\u001b[0m model_dt, metrics_dt \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m model_lg, metrics_lg \u001b[38;5;241m=\u001b[39m run_model(svm, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlg\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train_scaled, y_train)\n\u001b[0;32m      4\u001b[0m model_svm, metrics_svm \u001b[38;5;241m=\u001b[39m run_model(dt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvm\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train_scaled, y_train)\n",
      "Cell \u001b[1;32mIn[28], line 28\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(model, classifier_name, X_train, y_train)\u001b[0m\n\u001b[0;32m     12\u001b[0m kf \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     13\u001b[0m                      shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m                      random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: make_scorer(accuracy_score),\n\u001b[0;32m     18\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: make_scorer(balanced_accuracy_score),  \n\u001b[0;32m     19\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: make_scorer(precision_score, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweighted\u001b[39m\u001b[38;5;124m\"\u001b[39m), \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m                                                response_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m,),\n\u001b[0;32m     26\u001b[0m }\n\u001b[1;32m---> 28\u001b[0m cross_val_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m metric_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m     37\u001b[0m mean_train \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mround\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(cross_val_results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]), \u001b[38;5;241m3\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metric_names]\n",
      "File \u001b[1;32mc:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    425\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    441\u001b[0m )\n\u001b[1;32m--> 443\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1064, in check_array\n    _assert_all_finite(\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 123, in _assert_all_finite\n    _assert_all_finite_element_wise(\n  File \"c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 172, in _assert_all_finite_element_wise\n    raise ValueError(msg_err)\nValueError: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n"
     ]
    }
   ],
   "source": [
    "model_rf, metrics_rf = run_model(rf, \"Random Forest\", X_train, y_train)\n",
    "model_dt, metrics_dt = run_model(lg, \"dt\", X_train, y_train)\n",
    "model_lg, metrics_lg = run_model(svm, \"lg\", X_train_scaled, y_train)\n",
    "model_svm, metrics_svm = run_model(dt, \"svm\", X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Fit Time</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean Train</th>\n",
       "      <th>Std Train</th>\n",
       "      <th>Mean Test</th>\n",
       "      <th>Std Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.306</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.306</td>\n",
       "      <td>balanced_accuracy</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.306</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.306</td>\n",
       "      <td>recall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.306</td>\n",
       "      <td>f1_weighted</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.306</td>\n",
       "      <td>roc_auc_ovr_weighted</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classifier  Fit Time                Metric  Mean Train  Std Train  \\\n",
       "0  Random Forest     0.306              accuracy         1.0        0.0   \n",
       "1  Random Forest     0.306     balanced_accuracy         1.0        0.0   \n",
       "2  Random Forest     0.306             precision         1.0        0.0   \n",
       "3  Random Forest     0.306                recall         1.0        0.0   \n",
       "4  Random Forest     0.306           f1_weighted         1.0        0.0   \n",
       "5  Random Forest     0.306  roc_auc_ovr_weighted         1.0        0.0   \n",
       "\n",
       "   Mean Test  Std Test  \n",
       "0      0.960     0.026  \n",
       "1      0.958     0.028  \n",
       "2      0.961     0.026  \n",
       "3      0.960     0.026  \n",
       "4      0.960     0.026  \n",
       "5      0.989     0.014  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
