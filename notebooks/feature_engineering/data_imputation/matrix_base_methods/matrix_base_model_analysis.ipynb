{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use baysian, IterSVD, Matrix Factorization, Soft impute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fancyimpute import IterativeSVD, SoftImpute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ageatscreening</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MMSE0m</th>\n",
       "      <th>HipsASMbaseline</th>\n",
       "      <th>HipsContrastbaseline</th>\n",
       "      <th>HipsCorelationbaseline</th>\n",
       "      <th>HipsVariancebaseline</th>\n",
       "      <th>HipsSumAveragebaseline</th>\n",
       "      <th>...</th>\n",
       "      <th>ERCsContrastbaseline</th>\n",
       "      <th>ERCsCorelationbaseline</th>\n",
       "      <th>ERCsVariancebaseline</th>\n",
       "      <th>ERCsSumAveragebaseline</th>\n",
       "      <th>ERCsSumVariancebaseline</th>\n",
       "      <th>ERCsEntropybaseline</th>\n",
       "      <th>ERCsClusterShadebaseline</th>\n",
       "      <th>ERCs_thicknessbaseline</th>\n",
       "      <th>ERCsVolumebaseline</th>\n",
       "      <th>HipposcampusVolumebaseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81.3479</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.27</td>\n",
       "      <td>0.63</td>\n",
       "      <td>218.30</td>\n",
       "      <td>28.37</td>\n",
       "      <td>...</td>\n",
       "      <td>253.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>208.65</td>\n",
       "      <td>23.39</td>\n",
       "      <td>581.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2568.19</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>3047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>67.6904</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>147.64</td>\n",
       "      <td>0.55</td>\n",
       "      <td>173.64</td>\n",
       "      <td>44.72</td>\n",
       "      <td>...</td>\n",
       "      <td>220.88</td>\n",
       "      <td>0.48</td>\n",
       "      <td>215.70</td>\n",
       "      <td>33.74</td>\n",
       "      <td>641.90</td>\n",
       "      <td>3.33</td>\n",
       "      <td>4113.01</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>3449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73.8027</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>199.66</td>\n",
       "      <td>0.55</td>\n",
       "      <td>222.27</td>\n",
       "      <td>41.18</td>\n",
       "      <td>...</td>\n",
       "      <td>220.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>232.18</td>\n",
       "      <td>29.18</td>\n",
       "      <td>708.36</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1388.41</td>\n",
       "      <td>3.18</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>3441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>84.5945</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>184.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>201.55</td>\n",
       "      <td>43.04</td>\n",
       "      <td>...</td>\n",
       "      <td>198.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>220.48</td>\n",
       "      <td>26.68</td>\n",
       "      <td>683.50</td>\n",
       "      <td>2.77</td>\n",
       "      <td>-2506.55</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>2875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>73.9726</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>233.02</td>\n",
       "      <td>0.48</td>\n",
       "      <td>229.88</td>\n",
       "      <td>39.46</td>\n",
       "      <td>...</td>\n",
       "      <td>196.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>210.63</td>\n",
       "      <td>26.60</td>\n",
       "      <td>645.95</td>\n",
       "      <td>2.72</td>\n",
       "      <td>-1164.02</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>2700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RID  Gender  Ageatscreening  Diagnosis  MMSE0m  HipsASMbaseline  \\\n",
       "0    3       0         81.3479          3    20.0              NaN   \n",
       "1    4       0         67.6904          1    27.0             0.06   \n",
       "2    5       0         73.8027          0    29.0             0.10   \n",
       "3    8       1         84.5945          0    28.0             0.08   \n",
       "4   10       1         73.9726          3    24.0             0.11   \n",
       "\n",
       "   HipsContrastbaseline  HipsCorelationbaseline  HipsVariancebaseline  \\\n",
       "0                158.27                    0.63                218.30   \n",
       "1                147.64                    0.55                173.64   \n",
       "2                199.66                    0.55                222.27   \n",
       "3                184.21                    0.53                201.55   \n",
       "4                233.02                    0.48                229.88   \n",
       "\n",
       "   HipsSumAveragebaseline  ...  ERCsContrastbaseline  ERCsCorelationbaseline  \\\n",
       "0                   28.37  ...                253.10                    0.40   \n",
       "1                   44.72  ...                220.88                    0.48   \n",
       "2                   41.18  ...                220.37                    0.54   \n",
       "3                   43.04  ...                198.42                    0.54   \n",
       "4                   39.46  ...                196.55                    0.53   \n",
       "\n",
       "   ERCsVariancebaseline  ERCsSumAveragebaseline  ERCsSumVariancebaseline  \\\n",
       "0                208.65                   23.39                   581.50   \n",
       "1                215.70                   33.74                   641.90   \n",
       "2                232.18                   29.18                   708.36   \n",
       "3                220.48                   26.68                   683.50   \n",
       "4                210.63                   26.60                   645.95   \n",
       "\n",
       "   ERCsEntropybaseline  ERCsClusterShadebaseline  ERCs_thicknessbaseline  \\\n",
       "0                  NaN                  -2568.19                    2.31   \n",
       "1                 3.33                   4113.01                    2.76   \n",
       "2                 2.87                  -1388.41                    3.18   \n",
       "3                 2.77                  -2506.55                    2.68   \n",
       "4                 2.72                  -1164.02                    2.64   \n",
       "\n",
       "   ERCsVolumebaseline  HipposcampusVolumebaseline  \n",
       "0              1176.0                      3047.0  \n",
       "1              1942.0                      3449.0  \n",
       "2              2044.0                      3441.0  \n",
       "3              1959.0                      2875.0  \n",
       "4              1397.0                      2700.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "load_dotenv()\n",
    "dataset_path=os.getenv(\"DATASET_PATH\")\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RID                            0\n",
       "Gender                         0\n",
       "Ageatscreening                 0\n",
       "Diagnosis                      0\n",
       "HipsSumAveragebaseline         1\n",
       "MMSE0m                         3\n",
       "ERCsASMbaseline                4\n",
       "HipsSumVariancebaseline        7\n",
       "HipsVariancebaseline           8\n",
       "ERCsEntropybaseline            9\n",
       "ERCsSumAveragebaseline        11\n",
       "ERCsSumVariancebaseline       13\n",
       "ERCsVariancebaseline          14\n",
       "HipsContrastbaseline          14\n",
       "ERCsVolumebaseline            14\n",
       "ERCsContrastbaseline          18\n",
       "HipsClusterShadebaseline      18\n",
       "HipposcampusVolumebaseline    19\n",
       "HipsCorelationbaseline        20\n",
       "HipsEntropybaseline           23\n",
       "HipsASMbaseline               25\n",
       "ERCsCorelationbaseline        28\n",
       "ERCsClusterShadebaseline      34\n",
       "ERCs_thicknessbaseline        37\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_data = dataset.isna().sum().sort_values()\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset.drop(\"Diagnosis\", axis=1),  \n",
    "    dataset[\"Diagnosis\"],  \n",
    "    test_size=0.3,  \n",
    "    random_state=42,  \n",
    ")\n",
    "\n",
    "X_combined = pd.concat([X_train, X_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeSVD] Iter 1: observed MAE=290.522514\n",
      "[IterativeSVD] Iter 2: observed MAE=197.616056\n",
      "[IterativeSVD] Iter 3: observed MAE=28.356853\n",
      "[IterativeSVD] Iter 4: observed MAE=1.697254\n",
      "[IterativeSVD] Iter 5: observed MAE=0.503289\n",
      "[SoftImpute] Max Singular Value of X_init = 403977.444542\n",
      "[SoftImpute] Iter 1: observed MAE=72.138084 rank=5\n",
      "[SoftImpute] Iter 2: observed MAE=72.589102 rank=5\n",
      "[SoftImpute] Iter 3: observed MAE=71.705811 rank=4\n",
      "[SoftImpute] Iter 4: observed MAE=71.252901 rank=4\n",
      "[SoftImpute] Iter 5: observed MAE=71.013974 rank=4\n",
      "[SoftImpute] Iter 6: observed MAE=70.906418 rank=4\n",
      "[SoftImpute] Iter 7: observed MAE=70.862595 rank=4\n",
      "[SoftImpute] Iter 8: observed MAE=70.841562 rank=4\n",
      "[SoftImpute] Iter 9: observed MAE=70.832763 rank=4\n",
      "[SoftImpute] Iter 10: observed MAE=70.830568 rank=4\n",
      "[SoftImpute] Iter 11: observed MAE=70.832055 rank=4\n",
      "[SoftImpute] Iter 12: observed MAE=70.835160 rank=4\n",
      "[SoftImpute] Iter 13: observed MAE=70.838895 rank=4\n",
      "[SoftImpute] Iter 14: observed MAE=70.842834 rank=4\n",
      "[SoftImpute] Iter 15: observed MAE=70.846764 rank=4\n",
      "[SoftImpute] Iter 16: observed MAE=70.850503 rank=4\n",
      "[SoftImpute] Iter 17: observed MAE=70.854126 rank=4\n",
      "[SoftImpute] Iter 18: observed MAE=70.857452 rank=4\n",
      "[SoftImpute] Iter 19: observed MAE=70.860543 rank=4\n",
      "[SoftImpute] Iter 20: observed MAE=70.863339 rank=4\n",
      "[SoftImpute] Iter 21: observed MAE=70.865878 rank=4\n",
      "[SoftImpute] Iter 22: observed MAE=70.868180 rank=4\n",
      "[SoftImpute] Iter 23: observed MAE=70.870322 rank=4\n",
      "[SoftImpute] Iter 24: observed MAE=70.872343 rank=4\n",
      "[SoftImpute] Iter 25: observed MAE=70.874314 rank=4\n",
      "[SoftImpute] Iter 26: observed MAE=70.876212 rank=4\n",
      "[SoftImpute] Iter 27: observed MAE=70.877992 rank=4\n",
      "[SoftImpute] Iter 28: observed MAE=70.879695 rank=4\n",
      "[SoftImpute] Iter 29: observed MAE=70.881297 rank=4\n",
      "[SoftImpute] Iter 30: observed MAE=70.882810 rank=4\n",
      "[SoftImpute] Iter 31: observed MAE=70.884230 rank=4\n",
      "[SoftImpute] Iter 32: observed MAE=70.885566 rank=4\n",
      "[SoftImpute] Iter 33: observed MAE=70.886824 rank=4\n",
      "[SoftImpute] Iter 34: observed MAE=70.888012 rank=4\n",
      "[SoftImpute] Iter 35: observed MAE=70.889153 rank=4\n",
      "[SoftImpute] Iter 36: observed MAE=70.890272 rank=4\n",
      "[SoftImpute] Iter 37: observed MAE=70.891335 rank=4\n",
      "[SoftImpute] Iter 38: observed MAE=70.892342 rank=4\n",
      "[SoftImpute] Iter 39: observed MAE=70.893300 rank=4\n",
      "[SoftImpute] Iter 40: observed MAE=70.894214 rank=4\n",
      "[SoftImpute] Iter 41: observed MAE=70.895084 rank=4\n",
      "[SoftImpute] Iter 42: observed MAE=70.895910 rank=4\n",
      "[SoftImpute] Iter 43: observed MAE=70.896695 rank=4\n",
      "[SoftImpute] Iter 44: observed MAE=70.897442 rank=4\n",
      "[SoftImpute] Iter 45: observed MAE=70.898152 rank=4\n",
      "[SoftImpute] Iter 46: observed MAE=70.898829 rank=4\n",
      "[SoftImpute] Iter 47: observed MAE=70.899474 rank=4\n",
      "[SoftImpute] Iter 48: observed MAE=70.900089 rank=4\n",
      "[SoftImpute] Iter 49: observed MAE=70.900675 rank=4\n",
      "[SoftImpute] Iter 50: observed MAE=70.901234 rank=4\n",
      "[SoftImpute] Iter 51: observed MAE=70.901766 rank=4\n",
      "[SoftImpute] Iter 52: observed MAE=70.902273 rank=4\n",
      "[SoftImpute] Iter 53: observed MAE=70.902756 rank=4\n",
      "[SoftImpute] Iter 54: observed MAE=70.903217 rank=4\n",
      "[SoftImpute] Iter 55: observed MAE=70.903657 rank=4\n",
      "[SoftImpute] Iter 56: observed MAE=70.904079 rank=4\n",
      "[SoftImpute] Iter 57: observed MAE=70.904483 rank=4\n",
      "[SoftImpute] Iter 58: observed MAE=70.904869 rank=4\n",
      "[SoftImpute] Iter 59: observed MAE=70.905238 rank=4\n",
      "[SoftImpute] Iter 60: observed MAE=70.905590 rank=4\n",
      "[SoftImpute] Iter 61: observed MAE=70.905927 rank=4\n",
      "[SoftImpute] Iter 62: observed MAE=70.906249 rank=4\n",
      "[SoftImpute] Iter 63: observed MAE=70.906556 rank=4\n",
      "[SoftImpute] Iter 64: observed MAE=70.906850 rank=4\n",
      "[SoftImpute] Iter 65: observed MAE=70.907131 rank=4\n",
      "[SoftImpute] Iter 66: observed MAE=70.907399 rank=4\n",
      "[SoftImpute] Iter 67: observed MAE=70.907656 rank=4\n",
      "[SoftImpute] Iter 68: observed MAE=70.907901 rank=4\n",
      "[SoftImpute] Iter 69: observed MAE=70.908136 rank=4\n",
      "[SoftImpute] Iter 70: observed MAE=70.908371 rank=4\n",
      "[SoftImpute] Iter 71: observed MAE=70.908597 rank=4\n",
      "[SoftImpute] Iter 72: observed MAE=70.908814 rank=4\n",
      "[SoftImpute] Iter 73: observed MAE=70.909022 rank=4\n",
      "[SoftImpute] Iter 74: observed MAE=70.909222 rank=4\n",
      "[SoftImpute] Iter 75: observed MAE=70.909415 rank=4\n",
      "[SoftImpute] Iter 76: observed MAE=70.909600 rank=4\n",
      "[SoftImpute] Iter 77: observed MAE=70.909778 rank=4\n",
      "[SoftImpute] Iter 78: observed MAE=70.909953 rank=4\n",
      "[SoftImpute] Iter 79: observed MAE=70.910122 rank=4\n",
      "[SoftImpute] Iter 80: observed MAE=70.910284 rank=4\n",
      "[SoftImpute] Iter 81: observed MAE=70.910439 rank=4\n",
      "[SoftImpute] Iter 82: observed MAE=70.910593 rank=4\n",
      "[SoftImpute] Iter 83: observed MAE=70.910741 rank=4\n",
      "[SoftImpute] Iter 84: observed MAE=70.910883 rank=4\n",
      "[SoftImpute] Iter 85: observed MAE=70.911020 rank=4\n",
      "[SoftImpute] Iter 86: observed MAE=70.911151 rank=4\n",
      "[SoftImpute] Iter 87: observed MAE=70.911277 rank=4\n",
      "[SoftImpute] Iter 88: observed MAE=70.911398 rank=4\n",
      "[SoftImpute] Iter 89: observed MAE=70.911514 rank=4\n",
      "[SoftImpute] Iter 90: observed MAE=70.911626 rank=4\n",
      "[SoftImpute] Iter 91: observed MAE=70.911734 rank=4\n",
      "[SoftImpute] Iter 92: observed MAE=70.911840 rank=4\n",
      "[SoftImpute] Iter 93: observed MAE=70.911941 rank=4\n",
      "[SoftImpute] Iter 94: observed MAE=70.912038 rank=4\n",
      "[SoftImpute] Iter 95: observed MAE=70.912132 rank=4\n",
      "[SoftImpute] Iter 96: observed MAE=70.912222 rank=4\n",
      "[SoftImpute] Iter 97: observed MAE=70.912309 rank=4\n",
      "[SoftImpute] Iter 98: observed MAE=70.912393 rank=4\n",
      "[SoftImpute] Iter 99: observed MAE=70.912473 rank=4\n",
      "[SoftImpute] Iter 100: observed MAE=70.912552 rank=4\n",
      "[SoftImpute] Stopped after iteration 100 for lambda=8079.548891\n"
     ]
    }
   ],
   "source": [
    "# Initialize IterativeSVD for imputation\n",
    "iterative_svd = IterativeSVD()\n",
    "softimpute = SoftImpute()\n",
    "\n",
    "# Perform IterativeSVD Imputation on the combined dataset\n",
    "X_combined_imputed_iterative = iterative_svd.fit_transform(X_combined)\n",
    "X_train_imputed_iterative = X_combined_imputed_iterative[:len(X_train), :]\n",
    "X_test_imputed_iterative = X_combined_imputed_iterative[len(X_train):, :]\n",
    "\n",
    "# Perform SoftImpute on the combined dataset\n",
    "X_combined_imputed_soft = softimpute.fit_transform(X_combined)\n",
    "X_train_imputed_soft = X_combined_imputed_soft[:len(X_train), :]\n",
    "X_test_imputed_soft = X_combined_imputed_soft[len(X_train):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_svd = pd.DataFrame(X_train_imputed_iterative, columns=X_train.columns)\n",
    "X_test_imputed_svd = pd.DataFrame(X_test_imputed_iterative, columns=X_test.columns)\n",
    "\n",
    "X_train_imputed_sm = pd.DataFrame(X_train_imputed_soft, columns=X_train.columns)\n",
    "X_test_imputed_sm = pd.DataFrame(X_test_imputed_soft, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed_sm.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def nested_cross_val(model, grid):\n",
    "\n",
    "    # configure the outer loop cross-validation procedure\n",
    "    cv_outer = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # configure the inner loop cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "    # enumerate splits\n",
    "    outer_results = list()\n",
    "    inner_results = list()\n",
    "\n",
    "    for train_ix, test_ix in cv_outer.split(X_train_imputed_sm):\n",
    "\n",
    "        # split data\n",
    "        xtrain, xtest = X_train_imputed_sm.loc[train_ix, :], X_train_imputed_sm.loc[test_ix, :]\n",
    "        ytrain, ytest = y_train[train_ix], y_train[test_ix]\n",
    "\n",
    "        # define search\n",
    "        search = GridSearchCV(\n",
    "            model, grid, scoring='accuracy', cv=cv_inner, refit=True)\n",
    "\n",
    "        # execute search\n",
    "        search.fit(xtrain, ytrain)\n",
    "\n",
    "        # evaluate model on the hold out dataset\n",
    "        yhat = search.predict(xtest)\n",
    "\n",
    "        # evaluate the model\n",
    "        accuracy = accuracy_score(ytest, yhat)\n",
    "\n",
    "        # store the result\n",
    "        outer_results.append(accuracy)\n",
    "        \n",
    "        inner_results.append(search.best_score_)\n",
    "\n",
    "        # report progress\n",
    "        print(' >> accuracy_outer=%.3f, accuracy_inner=%.3f, cfg=%s' %\n",
    "              (accuracy, search.best_score_, search.best_params_))\n",
    "\n",
    "    # summarize the estimated performance of the model\n",
    "    print()\n",
    "    print('accuracy_outer: %.3f +- %.3f' %\n",
    "          (np.mean(outer_results), np.std(outer_results)))\n",
    "    print('accuracy_inner: %.3f +- %.3f' %\n",
    "          (np.mean(inner_results), np.std(inner_results)))\n",
    "\n",
    "    return search.fit(X_train_imputed_sm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param = dict(\n",
    "    n_estimators=[10, 50, 100, 200],\n",
    "    min_samples_split=[0.1, 0.3, 0.5, 1.0],\n",
    "    max_depth=[1,2,3,None],\n",
    "    )\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    min_samples_split=2,\n",
    "    max_depth=3,\n",
    "    random_state=0,\n",
    "    n_jobs=-1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> accuracy_outer=0.682, accuracy_inner=0.647, cfg={'max_depth': None, 'min_samples_split': 0.1, 'n_estimators': 200}\n",
      " >> accuracy_outer=0.600, accuracy_inner=0.635, cfg={'max_depth': None, 'min_samples_split': 0.1, 'n_estimators': 50}\n",
      " >> accuracy_outer=0.765, accuracy_inner=0.641, cfg={'max_depth': None, 'min_samples_split': 0.1, 'n_estimators': 100}\n",
      " >> accuracy_outer=0.541, accuracy_inner=0.659, cfg={'max_depth': None, 'min_samples_split': 0.1, 'n_estimators': 50}\n",
      " >> accuracy_outer=0.635, accuracy_inner=0.624, cfg={'max_depth': None, 'min_samples_split': 0.1, 'n_estimators': 200}\n",
      "\n",
      "accuracy_outer: 0.645 +- 0.076\n",
      "accuracy_inner: 0.641 +- 0.012\n"
     ]
    }
   ],
   "source": [
    "rf_search = nested_cross_val(rf, rf_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7435294117647059\n",
      "Test accuracy:  0.5300546448087432\n"
     ]
    }
   ],
   "source": [
    "# let's get the predictions\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_preds = rf_search.predict(X_train)\n",
    "X_test_preds = rf_search.predict(X_test)\n",
    "\n",
    "# let's examine the accuracy\n",
    "print('Train accuracy: ', accuracy_score(y_train, X_train_preds))\n",
    "print('Test accuracy: ', accuracy_score(y_test, X_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score, balanced_accuracy_score, make_scorer\n",
    "import numpy as np\n",
    "\n",
    "def run_random_forest(classifier_name, imp_method, X_train, y_train):\n",
    "\n",
    "        # Initialize the Random Forest with class weight balancing\n",
    "        rf = RandomForestClassifier(n_estimators=100,\n",
    "                                    max_depth=5,\n",
    "                                    random_state=42,\n",
    "                                    class_weight=\"balanced\",\n",
    "        )\n",
    "        \n",
    "        kf = StratifiedKFold(n_splits=5,\n",
    "                             shuffle=True,\n",
    "                             random_state=42,\n",
    "        )\n",
    "        \n",
    "        metrics = {\"accuracy\": make_scorer(accuracy_score),\n",
    "                   \"balanced_accuracy\": make_scorer(balanced_accuracy_score),  \n",
    "                   \"precision\": make_scorer(precision_score, average=\"weighted\"), \n",
    "                   \"recall\": make_scorer(recall_score, average=\"weighted\"), \n",
    "                   \"f1_weighted\": make_scorer(f1_score, average=\"weighted\"),\n",
    "                   \"roc_auc_ovr_weighted\": make_scorer(roc_auc_score, \n",
    "                                                       average=\"weighted\", \n",
    "                                                       multi_class=\"ovr\", \n",
    "                                                       response_method=\"predict_proba\",),\n",
    "        }\n",
    "        \n",
    "        cross_val_results = cross_validate(rf,\n",
    "                                           X_train,\n",
    "                                           y_train,\n",
    "                                           cv=kf,\n",
    "                                           scoring=metrics,\n",
    "                                           return_train_score=True,\n",
    "        )\n",
    "                \n",
    "        metric_names = list(metrics.keys())\n",
    "        mean_train = [round(np.mean(cross_val_results[f\"train_{metric}\"]), 3) for metric in metric_names]\n",
    "        std_train = [round(np.std(cross_val_results[f\"train_{metric}\"]), 3) for metric in metric_names]\n",
    "        mean_test = [round(np.mean(cross_val_results[f\"test_{metric}\"]), 3) for metric in metric_names]\n",
    "        std_test = [round(np.std(cross_val_results[f\"test_{metric}\"]), 3) for metric in metric_names]\n",
    "        time = round(np.mean(cross_val_results[f\"fit_time\"]), 3)\n",
    "                \n",
    "        cv_metrics_df = pd.DataFrame({\n",
    "                \"Classifier\": classifier_name,\n",
    "                \"Imputation\": imp_method,\n",
    "                \"Fit Time\": time,\n",
    "                \"Metric\": metric_names,\n",
    "                \"Mean Train\": mean_train,\n",
    "                \"Std Train\": std_train,\n",
    "                \"Mean Test\": mean_test,\n",
    "                \"Std Test\": std_test,\n",
    "        })\n",
    "        \n",
    "        fit_model = rf.fit(X_train, y_train)\n",
    "        \n",
    "        return fit_model, cv_metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model, svd_metrics = run_random_forest(\"Random Forest\", \"IterSVD\", X_train_imputed_svd, y_train)\n",
    "soft_model, soft_metrics = run_random_forest(\"Random Forest\", \"SoftImpute\", X_train_imputed_soft, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean Train</th>\n",
       "      <th>Std Train</th>\n",
       "      <th>Mean Test</th>\n",
       "      <th>Std Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th>Imputation</th>\n",
       "      <th>Fit Time</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">Random Forest</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">IterSVD</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.389</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <td>0.986</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">SoftImpute</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.274</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.905</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        Mean Train  Std Train  \\\n",
       "Classifier    Imputation Fit Time Metric                                        \n",
       "Random Forest IterSVD    0.389    accuracy                   0.907      0.010   \n",
       "                                  balanced_accuracy          0.914      0.008   \n",
       "                                  precision                  0.911      0.008   \n",
       "                                  recall                     0.907      0.010   \n",
       "                                  f1_weighted                0.905      0.010   \n",
       "                                  roc_auc_ovr_weighted       0.986      0.002   \n",
       "              SoftImpute 0.274    accuracy                   0.906      0.009   \n",
       "                                  balanced_accuracy          0.912      0.011   \n",
       "                                  precision                  0.911      0.008   \n",
       "                                  recall                     0.906      0.009   \n",
       "                                  f1_weighted                0.905      0.009   \n",
       "                                  roc_auc_ovr_weighted       0.985      0.002   \n",
       "\n",
       "                                                        Mean Test  Std Test  \n",
       "Classifier    Imputation Fit Time Metric                                     \n",
       "Random Forest IterSVD    0.389    accuracy                  0.638     0.020  \n",
       "                                  balanced_accuracy         0.565     0.018  \n",
       "                                  precision                 0.621     0.008  \n",
       "                                  recall                    0.638     0.020  \n",
       "                                  f1_weighted               0.617     0.015  \n",
       "                                  roc_auc_ovr_weighted      0.831     0.028  \n",
       "              SoftImpute 0.274    accuracy                  0.621     0.029  \n",
       "                                  balanced_accuracy         0.555     0.021  \n",
       "                                  precision                 0.603     0.035  \n",
       "                                  recall                    0.621     0.029  \n",
       "                                  f1_weighted               0.602     0.031  \n",
       "                                  roc_auc_ovr_weighted      0.830     0.018  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df = pd.concat([svd_metrics, soft_metrics])\n",
    "validation_df_report = validation_df.set_index([\"Classifier\", \"Imputation\", \"Fit Time\", \"Metric\"])\n",
    "validation_df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df.to_csv(\"C:/Users/steve/Desktop/Notebooks/Thesis-Project/Datasets/processed/imputed_methods/matrix_base/validation_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def eval_random_forest(classifier_name, imp_method, model, X_train, X_test, y_train, y_test):\n",
    "        \n",
    "        start_time = time.time()\n",
    "        # Get predicted probabilities for ROC AUC\n",
    "        pred_train_proba = model.predict_proba(X_train)\n",
    "        pred_test_proba = model.predict_proba(X_test)\n",
    "        \n",
    "        # Get predicted accuracy values\n",
    "        pred_train = model.predict(X_train)\n",
    "        pred_test = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics_train = {\n",
    "                \"Accuracy\": round(accuracy_score(y_train, pred_train), 3),\n",
    "                \"Balanced Accuracy\": round(balanced_accuracy_score(y_train, pred_train), 3),\n",
    "                \"Precision\": round(precision_score(y_train, pred_train, average=\"weighted\"), 3),\n",
    "                \"Recall\": round(recall_score(y_train, pred_train, average=\"weighted\"), 3),\n",
    "                \"F1-Score\": round(f1_score(y_train, pred_train, average=\"weighted\"), 3),\n",
    "                \"ROC-AUC\": round(roc_auc_score(y_train, pred_train_proba, average=\"weighted\", multi_class=\"ovr\"),3,),\n",
    "        }\n",
    "        \n",
    "        metrics_test = {\n",
    "                \"Accuracy\": round(accuracy_score(y_test, pred_test), 3),\n",
    "                \"Balanced Accuracy\": round(balanced_accuracy_score(y_test, pred_test), 3),\n",
    "                \"Precision\": round(precision_score(y_test, pred_test, average=\"weighted\"), 3),\n",
    "                \"Recall\": round(recall_score(y_test, pred_test, average=\"weighted\"), 3),\n",
    "                \"F1-Score\": round(f1_score(y_test, pred_test, average=\"weighted\"), 3),\n",
    "                \"ROC-AUC\": round(roc_auc_score(y_test, pred_test_proba, average=\"weighted\", multi_class=\"ovr\"),3,),\n",
    "        }\n",
    "                \n",
    "        elapsed_time = time.time() - start_time\n",
    "    \n",
    "        # Create the DataFrame without additional rounding\n",
    "        pred_metrics_df = pd.DataFrame({\n",
    "                \"Classifier\": classifier_name,\n",
    "                \"Imputation\": imp_method,\n",
    "                \"Classification Time\": round(elapsed_time, 3),\n",
    "                \"Metric\": metrics_train.keys(),\n",
    "                \"Train data\": metrics_train.values(),\n",
    "                \"Test data\": metrics_test.values(),\n",
    "    })\n",
    "        \n",
    "        return pred_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svd = eval_random_forest(\"Random Forest\", \"IterSVD\", svd_model, X_train_imputed_svd, X_test_imputed_svd, y_train, y_test)\n",
    "pred_soft = eval_random_forest(\"Random Forest\", \"SoftImpute\", soft_model, X_train_imputed_soft, X_test_imputed_soft, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Train data</th>\n",
       "      <th>Test data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th>Imputation</th>\n",
       "      <th>Classification Time</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">Random Forest</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">IterSVD</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.124</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.878</td>\n",
       "      <td>0.557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC-AUC</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">SoftImpute</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.085</th>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.894</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC-AUC</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                Train data  \\\n",
       "Classifier    Imputation Classification Time Metric                          \n",
       "Random Forest IterSVD    0.124               Accuracy                0.878   \n",
       "                                             Balanced Accuracy       0.886   \n",
       "                                             Precision               0.882   \n",
       "                                             Recall                  0.878   \n",
       "                                             F1-Score                0.875   \n",
       "                                             ROC-AUC                 0.979   \n",
       "              SoftImpute 0.085               Accuracy                0.889   \n",
       "                                             Balanced Accuracy       0.897   \n",
       "                                             Precision               0.894   \n",
       "                                             Recall                  0.889   \n",
       "                                             F1-Score                0.887   \n",
       "                                             ROC-AUC                 0.981   \n",
       "\n",
       "                                                                Test data  \n",
       "Classifier    Imputation Classification Time Metric                        \n",
       "Random Forest IterSVD    0.124               Accuracy               0.557  \n",
       "                                             Balanced Accuracy      0.568  \n",
       "                                             Precision              0.549  \n",
       "                                             Recall                 0.557  \n",
       "                                             F1-Score               0.543  \n",
       "                                             ROC-AUC                0.810  \n",
       "              SoftImpute 0.085               Accuracy               0.546  \n",
       "                                             Balanced Accuracy      0.560  \n",
       "                                             Precision              0.534  \n",
       "                                             Recall                 0.546  \n",
       "                                             F1-Score               0.531  \n",
       "                                             ROC-AUC                0.818  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.concat([pred_svd, pred_soft])\n",
    "prediction_df_report = prediction_df.set_index([\"Classifier\", \"Imputation\",\t\"Classification Time\", \"Metric\"])\n",
    "prediction_df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df.to_csv(\"C:/Users/steve/Desktop/Notebooks/Thesis-Project/Datasets/processed/imputed_methods/matrix_base/prediction_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
