{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries for EDA\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pingouin as pg\n",
    "from sklearn.preprocessing import StandardScaler \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ageatscreening</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MMSE0m</th>\n",
       "      <th>HipsASMbaseline</th>\n",
       "      <th>HipsContrastbaseline</th>\n",
       "      <th>HipsCorelationbaseline</th>\n",
       "      <th>HipsVariancebaseline</th>\n",
       "      <th>HipsSumAveragebaseline</th>\n",
       "      <th>...</th>\n",
       "      <th>ERCsContrastbaseline</th>\n",
       "      <th>ERCsCorelationbaseline</th>\n",
       "      <th>ERCsVariancebaseline</th>\n",
       "      <th>ERCsSumAveragebaseline</th>\n",
       "      <th>ERCsSumVariancebaseline</th>\n",
       "      <th>ERCsEntropybaseline</th>\n",
       "      <th>ERCsClusterShadebaseline</th>\n",
       "      <th>ERCs_thicknessbaseline</th>\n",
       "      <th>ERCsVolumebaseline</th>\n",
       "      <th>HipposcampusVolumebaseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81.3479</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.27</td>\n",
       "      <td>0.63</td>\n",
       "      <td>218.30</td>\n",
       "      <td>28.37</td>\n",
       "      <td>...</td>\n",
       "      <td>253.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>208.65</td>\n",
       "      <td>23.39</td>\n",
       "      <td>581.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2568.19</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>3047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>67.6904</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>147.64</td>\n",
       "      <td>0.55</td>\n",
       "      <td>173.64</td>\n",
       "      <td>44.72</td>\n",
       "      <td>...</td>\n",
       "      <td>220.88</td>\n",
       "      <td>0.48</td>\n",
       "      <td>215.70</td>\n",
       "      <td>33.74</td>\n",
       "      <td>641.90</td>\n",
       "      <td>3.33</td>\n",
       "      <td>4113.01</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>3449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73.8027</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>199.66</td>\n",
       "      <td>0.55</td>\n",
       "      <td>222.27</td>\n",
       "      <td>41.18</td>\n",
       "      <td>...</td>\n",
       "      <td>220.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>232.18</td>\n",
       "      <td>29.18</td>\n",
       "      <td>708.36</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1388.41</td>\n",
       "      <td>3.18</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>3441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>84.5945</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>184.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>201.55</td>\n",
       "      <td>43.04</td>\n",
       "      <td>...</td>\n",
       "      <td>198.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>220.48</td>\n",
       "      <td>26.68</td>\n",
       "      <td>683.50</td>\n",
       "      <td>2.77</td>\n",
       "      <td>-2506.55</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>2875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>73.9726</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>233.02</td>\n",
       "      <td>0.48</td>\n",
       "      <td>229.88</td>\n",
       "      <td>39.46</td>\n",
       "      <td>...</td>\n",
       "      <td>196.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>210.63</td>\n",
       "      <td>26.60</td>\n",
       "      <td>645.95</td>\n",
       "      <td>2.72</td>\n",
       "      <td>-1164.02</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>2700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RID  Gender  Ageatscreening  Diagnosis  MMSE0m  HipsASMbaseline  \\\n",
       "0    3       0         81.3479          3    20.0              NaN   \n",
       "1    4       0         67.6904          1    27.0             0.06   \n",
       "2    5       0         73.8027          0    29.0             0.10   \n",
       "3    8       1         84.5945          0    28.0             0.08   \n",
       "4   10       1         73.9726          3    24.0             0.11   \n",
       "\n",
       "   HipsContrastbaseline  HipsCorelationbaseline  HipsVariancebaseline  \\\n",
       "0                158.27                    0.63                218.30   \n",
       "1                147.64                    0.55                173.64   \n",
       "2                199.66                    0.55                222.27   \n",
       "3                184.21                    0.53                201.55   \n",
       "4                233.02                    0.48                229.88   \n",
       "\n",
       "   HipsSumAveragebaseline  ...  ERCsContrastbaseline  ERCsCorelationbaseline  \\\n",
       "0                   28.37  ...                253.10                    0.40   \n",
       "1                   44.72  ...                220.88                    0.48   \n",
       "2                   41.18  ...                220.37                    0.54   \n",
       "3                   43.04  ...                198.42                    0.54   \n",
       "4                   39.46  ...                196.55                    0.53   \n",
       "\n",
       "   ERCsVariancebaseline  ERCsSumAveragebaseline  ERCsSumVariancebaseline  \\\n",
       "0                208.65                   23.39                   581.50   \n",
       "1                215.70                   33.74                   641.90   \n",
       "2                232.18                   29.18                   708.36   \n",
       "3                220.48                   26.68                   683.50   \n",
       "4                210.63                   26.60                   645.95   \n",
       "\n",
       "   ERCsEntropybaseline  ERCsClusterShadebaseline  ERCs_thicknessbaseline  \\\n",
       "0                  NaN                  -2568.19                    2.31   \n",
       "1                 3.33                   4113.01                    2.76   \n",
       "2                 2.87                  -1388.41                    3.18   \n",
       "3                 2.77                  -2506.55                    2.68   \n",
       "4                 2.72                  -1164.02                    2.64   \n",
       "\n",
       "   ERCsVolumebaseline  HipposcampusVolumebaseline  \n",
       "0              1176.0                      3047.0  \n",
       "1              1942.0                      3449.0  \n",
       "2              2044.0                      3441.0  \n",
       "3              1959.0                      2875.0  \n",
       "4              1397.0                      2700.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "load_dotenv()\n",
    "dataset_path=os.getenv(\"DATASET_PATH\")\n",
    "dataset = pd.read_csv(dataset_path)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group one seperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_one = dataset[dataset[\"Diagnosis\"] == 0]\n",
    "group_two = dataset[dataset[\"Diagnosis\"] == 2]\n",
    "\n",
    "combined_group_one = pd.concat([group_one, group_two], ignore_index = True)\n",
    "combined_group_one[\"Diagnosis\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ageatscreening</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MMSE0m</th>\n",
       "      <th>HipsASMbaseline</th>\n",
       "      <th>HipsContrastbaseline</th>\n",
       "      <th>HipsCorelationbaseline</th>\n",
       "      <th>HipsVariancebaseline</th>\n",
       "      <th>HipsSumAveragebaseline</th>\n",
       "      <th>...</th>\n",
       "      <th>ERCsContrastbaseline</th>\n",
       "      <th>ERCsCorelationbaseline</th>\n",
       "      <th>ERCsVariancebaseline</th>\n",
       "      <th>ERCsSumAveragebaseline</th>\n",
       "      <th>ERCsSumVariancebaseline</th>\n",
       "      <th>ERCsEntropybaseline</th>\n",
       "      <th>ERCsClusterShadebaseline</th>\n",
       "      <th>ERCs_thicknessbaseline</th>\n",
       "      <th>ERCsVolumebaseline</th>\n",
       "      <th>HipposcampusVolumebaseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73.8027</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>199.66</td>\n",
       "      <td>0.55</td>\n",
       "      <td>222.27</td>\n",
       "      <td>41.18</td>\n",
       "      <td>...</td>\n",
       "      <td>220.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>232.18</td>\n",
       "      <td>29.18</td>\n",
       "      <td>708.36</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1388.41</td>\n",
       "      <td>3.18</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>3441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>84.5945</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>184.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>201.55</td>\n",
       "      <td>43.04</td>\n",
       "      <td>...</td>\n",
       "      <td>198.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>220.48</td>\n",
       "      <td>26.68</td>\n",
       "      <td>683.50</td>\n",
       "      <td>2.77</td>\n",
       "      <td>-2506.55</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>2875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>78.6137</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>188.33</td>\n",
       "      <td>0.49</td>\n",
       "      <td>183.76</td>\n",
       "      <td>39.63</td>\n",
       "      <td>...</td>\n",
       "      <td>241.64</td>\n",
       "      <td>0.44</td>\n",
       "      <td>226.48</td>\n",
       "      <td>35.11</td>\n",
       "      <td>664.29</td>\n",
       "      <td>3.10</td>\n",
       "      <td>8478.33</td>\n",
       "      <td>3.01</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>3292.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>80.9068</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>161.28</td>\n",
       "      <td>0.54</td>\n",
       "      <td>174.53</td>\n",
       "      <td>35.94</td>\n",
       "      <td>...</td>\n",
       "      <td>221.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.12</td>\n",
       "      <td>4287.78</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2188.0</td>\n",
       "      <td>3603.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>65.5205</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>166.97</td>\n",
       "      <td>0.58</td>\n",
       "      <td>202.96</td>\n",
       "      <td>38.42</td>\n",
       "      <td>...</td>\n",
       "      <td>228.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>228.72</td>\n",
       "      <td>28.98</td>\n",
       "      <td>686.36</td>\n",
       "      <td>2.90</td>\n",
       "      <td>-1381.99</td>\n",
       "      <td>2.73</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>3695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>549</td>\n",
       "      <td>0</td>\n",
       "      <td>68.8849</td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>169.76</td>\n",
       "      <td>0.58</td>\n",
       "      <td>205.91</td>\n",
       "      <td>38.90</td>\n",
       "      <td>...</td>\n",
       "      <td>219.32</td>\n",
       "      <td>0.53</td>\n",
       "      <td>229.07</td>\n",
       "      <td>30.38</td>\n",
       "      <td>696.95</td>\n",
       "      <td>3.05</td>\n",
       "      <td>1.54</td>\n",
       "      <td>3.53</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>3801.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>658</td>\n",
       "      <td>0</td>\n",
       "      <td>72.2822</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>187.66</td>\n",
       "      <td>0.57</td>\n",
       "      <td>222.54</td>\n",
       "      <td>37.58</td>\n",
       "      <td>...</td>\n",
       "      <td>206.16</td>\n",
       "      <td>0.55</td>\n",
       "      <td>227.90</td>\n",
       "      <td>30.10</td>\n",
       "      <td>705.46</td>\n",
       "      <td>3.03</td>\n",
       "      <td>281.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2750.0</td>\n",
       "      <td>3345.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1244</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0877</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.13</td>\n",
       "      <td>152.52</td>\n",
       "      <td>0.63</td>\n",
       "      <td>208.54</td>\n",
       "      <td>35.72</td>\n",
       "      <td>...</td>\n",
       "      <td>220.67</td>\n",
       "      <td>0.53</td>\n",
       "      <td>231.71</td>\n",
       "      <td>30.18</td>\n",
       "      <td>706.18</td>\n",
       "      <td>3.02</td>\n",
       "      <td>28.95</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>3532.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1311</td>\n",
       "      <td>0</td>\n",
       "      <td>69.2110</td>\n",
       "      <td>2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>175.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>187.40</td>\n",
       "      <td>44.04</td>\n",
       "      <td>...</td>\n",
       "      <td>222.69</td>\n",
       "      <td>0.52</td>\n",
       "      <td>229.54</td>\n",
       "      <td>32.03</td>\n",
       "      <td>695.47</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2811.38</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1605.0</td>\n",
       "      <td>3219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>1412</td>\n",
       "      <td>0</td>\n",
       "      <td>59.4247</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>165.61</td>\n",
       "      <td>0.59</td>\n",
       "      <td>206.18</td>\n",
       "      <td>38.31</td>\n",
       "      <td>...</td>\n",
       "      <td>246.24</td>\n",
       "      <td>0.49</td>\n",
       "      <td>232.76</td>\n",
       "      <td>29.12</td>\n",
       "      <td>684.82</td>\n",
       "      <td>2.80</td>\n",
       "      <td>-996.13</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2073.0</td>\n",
       "      <td>3632.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RID  Gender  Ageatscreening  Diagnosis  MMSE0m  HipsASMbaseline  \\\n",
       "0       5       0         73.8027          0    29.0             0.10   \n",
       "1       8       1         84.5945          0    28.0             0.08   \n",
       "2      14       1         78.6137          0    29.0             0.12   \n",
       "3      15       0         80.9068          0    29.0             0.10   \n",
       "4      16       0         65.5205          0    28.0             0.12   \n",
       "..    ...     ...             ...        ...     ...              ...   \n",
       "273   549       0         68.8849          2    25.0             0.11   \n",
       "274   658       0         72.2822          2    30.0             0.13   \n",
       "275  1244       0         79.0877          2    24.0             0.13   \n",
       "276  1311       0         69.2110          2    29.0             0.10   \n",
       "277  1412       0         59.4247          2    30.0             0.11   \n",
       "\n",
       "     HipsContrastbaseline  HipsCorelationbaseline  HipsVariancebaseline  \\\n",
       "0                  199.66                    0.55                222.27   \n",
       "1                  184.21                    0.53                201.55   \n",
       "2                  188.33                    0.49                183.76   \n",
       "3                  161.28                    0.54                174.53   \n",
       "4                  166.97                    0.58                202.96   \n",
       "..                    ...                     ...                   ...   \n",
       "273                169.76                    0.58                205.91   \n",
       "274                187.66                    0.57                222.54   \n",
       "275                152.52                    0.63                208.54   \n",
       "276                175.27                    0.50                187.40   \n",
       "277                165.61                    0.59                206.18   \n",
       "\n",
       "     HipsSumAveragebaseline  ...  ERCsContrastbaseline  \\\n",
       "0                     41.18  ...                220.37   \n",
       "1                     43.04  ...                198.42   \n",
       "2                     39.63  ...                241.64   \n",
       "3                     35.94  ...                221.76   \n",
       "4                     38.42  ...                228.53   \n",
       "..                      ...  ...                   ...   \n",
       "273                   38.90  ...                219.32   \n",
       "274                   37.58  ...                206.16   \n",
       "275                   35.72  ...                220.67   \n",
       "276                   44.04  ...                222.69   \n",
       "277                   38.31  ...                246.24   \n",
       "\n",
       "     ERCsCorelationbaseline  ERCsVariancebaseline  ERCsSumAveragebaseline  \\\n",
       "0                      0.54                232.18                   29.18   \n",
       "1                      0.54                220.48                   26.68   \n",
       "2                      0.44                226.48                   35.11   \n",
       "3                      0.45                   NaN                   30.57   \n",
       "4                      0.50                228.72                   28.98   \n",
       "..                      ...                   ...                     ...   \n",
       "273                    0.53                229.07                   30.38   \n",
       "274                    0.55                227.90                   30.10   \n",
       "275                    0.53                231.71                   30.18   \n",
       "276                    0.52                229.54                   32.03   \n",
       "277                    0.49                232.76                   29.12   \n",
       "\n",
       "     ERCsSumVariancebaseline  ERCsEntropybaseline  ERCsClusterShadebaseline  \\\n",
       "0                     708.36                 2.87                  -1388.41   \n",
       "1                     683.50                 2.77                  -2506.55   \n",
       "2                     664.29                 3.10                   8478.33   \n",
       "3                        NaN                 3.12                   4287.78   \n",
       "4                     686.36                 2.90                  -1381.99   \n",
       "..                       ...                  ...                       ...   \n",
       "273                   696.95                 3.05                      1.54   \n",
       "274                   705.46                 3.03                    281.47   \n",
       "275                   706.18                 3.02                     28.95   \n",
       "276                   695.47                 3.05                   2811.38   \n",
       "277                   684.82                 2.80                   -996.13   \n",
       "\n",
       "     ERCs_thicknessbaseline  ERCsVolumebaseline  HipposcampusVolumebaseline  \n",
       "0                      3.18              2044.0                      3441.0  \n",
       "1                      2.68              1959.0                      2875.0  \n",
       "2                      3.01              1809.0                      3292.0  \n",
       "3                      2.90              2188.0                      3603.0  \n",
       "4                      2.73              1829.0                      3695.0  \n",
       "..                      ...                 ...                         ...  \n",
       "273                    3.53              2140.0                      3801.0  \n",
       "274                     NaN              2750.0                      3345.0  \n",
       "275                    2.98              2016.0                      3532.0  \n",
       "276                    2.98              1605.0                      3219.0  \n",
       "277                    2.98              2073.0                      3632.0  \n",
       "\n",
       "[278 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_group_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_group_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RID                            0\n",
       "Gender                         0\n",
       "Ageatscreening                 0\n",
       "Diagnosis                      0\n",
       "MMSE0m                         0\n",
       "HipsASMbaseline               13\n",
       "HipsContrastbaseline          11\n",
       "HipsCorelationbaseline        12\n",
       "HipsVariancebaseline           5\n",
       "HipsSumAveragebaseline         1\n",
       "HipsSumVariancebaseline        5\n",
       "HipsEntropybaseline           18\n",
       "HipsClusterShadebaseline      11\n",
       "ERCsASMbaseline                3\n",
       "ERCsContrastbaseline           2\n",
       "ERCsCorelationbaseline         4\n",
       "ERCsVariancebaseline           4\n",
       "ERCsSumAveragebaseline         7\n",
       "ERCsSumVariancebaseline        4\n",
       "ERCsEntropybaseline            3\n",
       "ERCsClusterShadebaseline      30\n",
       "ERCs_thicknessbaseline        19\n",
       "ERCsVolumebaseline            10\n",
       "HipposcampusVolumebaseline    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_group_one.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(189, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_group_one_drop = combined_group_one.dropna()\n",
    "combined_group_one_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((132, 23), (57, 23))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "\n",
    "# let's separate into training and testing set\n",
    "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(\n",
    "    combined_group_one_drop.drop(\"Diagnosis\", axis=1),  \n",
    "    combined_group_one_drop[\"Diagnosis\"],  \n",
    "    test_size=0.3,  \n",
    "    random_state=0,  \n",
    ")\n",
    "\n",
    "X_train_t.shape, X_test_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "0    130\n",
       "2     59\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_split_one = combined_group_one_drop[\"Diagnosis\"]\n",
    "y_split_one.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Diagnosis'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_split_one.value_counts(normalize=True).plot(kind=\"bar\",\n",
    "                                                color = \"#5e76fe\",\n",
    "                                                width = 0.4,\n",
    "                                                edgecolor = \"black\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((194, 23), (84, 23))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "\n",
    "# let's separate into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    combined_group_one.drop(\"Diagnosis\", axis=1),  \n",
    "    combined_group_one[\"Diagnosis\"],  \n",
    "    test_size=0.3,  \n",
    "    random_state=0,  \n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"imputer\", MeanMedianImputer(\n",
    "        imputation_method=\"mean\", \n",
    "        variables=[\n",
    "            'MMSE0m', 'HipsASMbaseline', 'HipsContrastbaseline',\n",
    "            'HipsCorelationbaseline', 'HipsVariancebaseline',\n",
    "            'HipsSumAveragebaseline', 'HipsSumVariancebaseline',\n",
    "            'HipsEntropybaseline', 'HipsClusterShadebaseline', \n",
    "            'ERCsASMbaseline', 'ERCsContrastbaseline', \n",
    "            'ERCsCorelationbaseline', 'ERCsVariancebaseline', \n",
    "            'ERCsSumAveragebaseline', 'ERCsSumVariancebaseline',\n",
    "            'ERCsEntropybaseline', 'ERCsClusterShadebaseline', \n",
    "            'ERCs_thicknessbaseline', 'ERCsVolumebaseline', \n",
    "            'HipposcampusVolumebaseline'\n",
    "        ]\n",
    "    )),\n",
    "    (\"scaler\", StandardScaler().set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train)\n",
    "\n",
    "# let's transform the data with the pipeline\n",
    "X_train_scaled = pipe.transform(X_train)\n",
    "X_test_scaled = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score, balanced_accuracy_score, make_scorer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def run_model(model, classifier_name, X_train, y_train):\n",
    "        \n",
    "        kf = StratifiedKFold(n_splits=5,\n",
    "                             shuffle=True,\n",
    "                             random_state=42,\n",
    "        )\n",
    "        \n",
    "        metrics = {\"accuracy\": make_scorer(accuracy_score),\n",
    "                   \"balanced_accuracy\": make_scorer(balanced_accuracy_score),  \n",
    "                   \"precision\": make_scorer(precision_score, average=\"weighted\"), \n",
    "                   \"recall\": make_scorer(recall_score, average=\"weighted\"), \n",
    "                   \"f1_weighted\": make_scorer(f1_score, average=\"weighted\"),\n",
    "                   \"roc_auc_ovr_weighted\": make_scorer(roc_auc_score, \n",
    "                                                       average=\"weighted\", \n",
    "                                                       multi_class=\"ovr\", \n",
    "                                                       response_method=\"predict_proba\",),\n",
    "        }\n",
    "        \n",
    "        cross_val_results = cross_validate(model,\n",
    "                                           X_train,\n",
    "                                           y_train,\n",
    "                                           cv=kf,\n",
    "                                           scoring=metrics,\n",
    "                                           return_train_score=True,\n",
    "        )\n",
    "                \n",
    "        metric_names = list(metrics.keys())\n",
    "        mean_train = [round(np.mean(cross_val_results[f\"train_{metric}\"]), 3) for metric in metric_names]\n",
    "        std_train = [round(np.std(cross_val_results[f\"train_{metric}\"]), 3) for metric in metric_names]\n",
    "        mean_test = [round(np.mean(cross_val_results[f\"test_{metric}\"]), 3) for metric in metric_names]\n",
    "        std_test = [round(np.std(cross_val_results[f\"test_{metric}\"]), 3) for metric in metric_names]\n",
    "        time = round(np.mean(cross_val_results[f\"fit_time\"]), 3)\n",
    "                \n",
    "        cv_metrics_df = pd.DataFrame({\n",
    "                \"Classifier\": classifier_name,\n",
    "                \"Fit Time\": time,\n",
    "                \"Metric\": metric_names,\n",
    "                \"Mean Train\": mean_train,\n",
    "                \"Std Train\": std_train,\n",
    "                \"Mean Test\": mean_test,\n",
    "                \"Std Test\": std_test,\n",
    "        })\n",
    "        \n",
    "        fit_model = model.fit(X_train, y_train)\n",
    "        \n",
    "        return fit_model, cv_metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42, class_weight=\"balanced\",\n",
    "        )\n",
    "lg = LogisticRegression(multi_class = \"auto\", solver = \"lbfgs\", max_iter = 1000, random_state = 42)\n",
    "\n",
    "svm = SVC(kernel ='rbf', decision_function_shape ='ovr', probability = True, random_state = 42)\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion ='gini', max_depth = 5, min_samples_split = 10,\n",
    "                                                  min_samples_leaf = 5, max_features = 'sqrt', random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\steve\\Desktop\\Notebooks\\Thesis-Project\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_rf, metrics_rf = run_model(rf, \"Random Forest\", X_train, y_train)\n",
    "model_dt, metrics_dt = run_model(dt, \"Decision Tree\", X_train, y_train)\n",
    "model_lg, metrics_lg = run_model(svm, \"Logistic Regression\", X_train_scaled, y_train)\n",
    "model_svm, metrics_svm = run_model(lg, \"Support Vector Machine\", X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean Train</th>\n",
       "      <th>Std Train</th>\n",
       "      <th>Mean Test</th>\n",
       "      <th>Std Test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th>Fit Time</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Random Forest</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.450</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Decision Tree</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.003</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.890</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <td>0.947</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Logistic Regression</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.010</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.963</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.940</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.963</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.963</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.962</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Support Vector Machine</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.007</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.924</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.940</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_ovr_weighted</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Mean Train  Std Train  \\\n",
       "Classifier             Fit Time Metric                                        \n",
       "Random Forest          0.450    accuracy                   0.996      0.003   \n",
       "                                balanced_accuracy          0.993      0.006   \n",
       "                                precision                  0.996      0.003   \n",
       "                                recall                     0.996      0.003   \n",
       "                                f1_weighted                0.996      0.003   \n",
       "                                roc_auc_ovr_weighted       1.000      0.000   \n",
       "Decision Tree          0.003    accuracy                   0.893      0.016   \n",
       "                                balanced_accuracy          0.840      0.024   \n",
       "                                precision                  0.893      0.017   \n",
       "                                recall                     0.893      0.016   \n",
       "                                f1_weighted                0.890      0.017   \n",
       "                                roc_auc_ovr_weighted       0.947      0.009   \n",
       "Logistic Regression    0.010    accuracy                   0.963      0.005   \n",
       "                                balanced_accuracy          0.940      0.009   \n",
       "                                precision                  0.963      0.005   \n",
       "                                recall                     0.963      0.005   \n",
       "                                f1_weighted                0.962      0.005   \n",
       "                                roc_auc_ovr_weighted       0.996      0.001   \n",
       "Support Vector Machine 0.007    accuracy                   0.939      0.016   \n",
       "                                balanced_accuracy          0.924      0.016   \n",
       "                                precision                  0.940      0.015   \n",
       "                                recall                     0.939      0.016   \n",
       "                                f1_weighted                0.939      0.016   \n",
       "                                roc_auc_ovr_weighted       0.981      0.004   \n",
       "\n",
       "                                                      Mean Test  Std Test  \n",
       "Classifier             Fit Time Metric                                     \n",
       "Random Forest          0.450    accuracy                  0.871     0.044  \n",
       "                                balanced_accuracy         0.808     0.070  \n",
       "                                precision                 0.873     0.047  \n",
       "                                recall                    0.871     0.044  \n",
       "                                f1_weighted               0.865     0.048  \n",
       "                                roc_auc_ovr_weighted      0.915     0.071  \n",
       "Decision Tree          0.003    accuracy                  0.809     0.064  \n",
       "                                balanced_accuracy         0.738     0.061  \n",
       "                                precision                 0.813     0.064  \n",
       "                                recall                    0.809     0.064  \n",
       "                                f1_weighted               0.804     0.060  \n",
       "                                roc_auc_ovr_weighted      0.797     0.082  \n",
       "Logistic Regression    0.010    accuracy                  0.907     0.040  \n",
       "                                balanced_accuracy         0.860     0.060  \n",
       "                                precision                 0.906     0.042  \n",
       "                                recall                    0.907     0.040  \n",
       "                                f1_weighted               0.904     0.042  \n",
       "                                roc_auc_ovr_weighted      0.952     0.030  \n",
       "Support Vector Machine 0.007    accuracy                  0.891     0.031  \n",
       "                                balanced_accuracy         0.868     0.045  \n",
       "                                precision                 0.897     0.031  \n",
       "                                recall                    0.891     0.031  \n",
       "                                f1_weighted               0.892     0.030  \n",
       "                                roc_auc_ovr_weighted      0.942     0.035  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df = pd.concat([metrics_rf, metrics_dt, metrics_lg, metrics_svm])\n",
    "validation_df_report = validation_df.set_index([\"Classifier\", \"Fit Time\", \"Metric\"])\n",
    "validation_df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def model_eval(model, classifier_name, X_train, X_test, y_train, y_test):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Ensure that y_train and y_test are 1D arrays\n",
    "    y_train = np.array(y_train).ravel()\n",
    "    y_test = np.array(y_test).ravel()\n",
    "    \n",
    "    # Get predicted probabilities for ROC AUC\n",
    "    pred_train_proba = model.predict_proba(X_train)\n",
    "    pred_test_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    # Get predicted classes for other metrics\n",
    "    pred_train = model.predict(X_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    \n",
    "    # For binary classification, use the probability of the positive class only:\n",
    "    roc_auc_train = roc_auc_score(y_train, pred_train_proba[:, 1])\n",
    "    roc_auc_test = roc_auc_score(y_test, pred_test_proba[:, 1])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics_train = {\n",
    "        \"accuracy\": round(accuracy_score(y_train, pred_train), 3),\n",
    "        \"balanced_accuracy\": round(balanced_accuracy_score(y_train, pred_train), 3),\n",
    "        \"precision\": round(precision_score(y_train, pred_train, average=\"weighted\"), 3),\n",
    "        \"recall\": round(recall_score(y_train, pred_train, average=\"weighted\"), 3),\n",
    "        \"f1_weighted\": round(f1_score(y_train, pred_train, average=\"weighted\"), 3),\n",
    "        \"roc_auc\": round(roc_auc_train, 3),\n",
    "    }\n",
    "    \n",
    "    metrics_test = {\n",
    "        \"accuracy\": round(accuracy_score(y_test, pred_test), 3),\n",
    "        \"balanced_accuracy\": round(balanced_accuracy_score(y_test, pred_test), 3),\n",
    "        \"precision\": round(precision_score(y_test, pred_test, average=\"weighted\"), 3),\n",
    "        \"recall\": round(recall_score(y_test, pred_test, average=\"weighted\"), 3),\n",
    "        \"f1_weighted\": round(f1_score(y_test, pred_test, average=\"weighted\"), 3),\n",
    "        \"roc_auc\": round(roc_auc_test, 3),\n",
    "    }\n",
    "            \n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Create the DataFrame without additional rounding issues\n",
    "    pred_metrics_df = pd.DataFrame({\n",
    "        \"Classifier\": classifier_name,\n",
    "        \"Classification Time\": round(elapsed_time, 3),\n",
    "        \"Metric\": list(metrics_train.keys()),\n",
    "        \"Train data\": list(metrics_train.values()),\n",
    "        \"Test data\": list(metrics_test.values()),\n",
    "    })\n",
    "    \n",
    "    return pred_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rf = model_eval(model_rf,\"Random Forest\", X_train, X_test, y_train, y_test)\n",
    "pred_dt = model_eval(model_dt,\"Decision Tree\", X_train, X_test, y_train, y_test)\n",
    "pred_lg = model_eval(model_lg,\"Logistic Regression\", X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "pred_svm = model_eval(model_svm,\"Support Vector Machine\", X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Train data</th>\n",
       "      <th>Test data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classifier</th>\n",
       "      <th>Classification Time</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Random Forest</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.123</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Decision Tree</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.041</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.893</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.929</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Logistic Regression</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.041</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.964</td>\n",
       "      <td>0.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.947</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.964</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.964</td>\n",
       "      <td>0.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.964</td>\n",
       "      <td>0.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Support Vector Machine</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">0.024</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.928</td>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.977</td>\n",
       "      <td>0.977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Train data  \\\n",
       "Classifier             Classification Time Metric                          \n",
       "Random Forest          0.123               accuracy                0.995   \n",
       "                                           balanced_accuracy       0.991   \n",
       "                                           precision               0.995   \n",
       "                                           recall                  0.995   \n",
       "                                           f1_weighted             0.995   \n",
       "                                           roc_auc                 1.000   \n",
       "Decision Tree          0.041               accuracy                0.897   \n",
       "                                           balanced_accuracy       0.838   \n",
       "                                           precision               0.898   \n",
       "                                           recall                  0.897   \n",
       "                                           f1_weighted             0.893   \n",
       "                                           roc_auc                 0.929   \n",
       "Logistic Regression    0.041               accuracy                0.964   \n",
       "                                           balanced_accuracy       0.947   \n",
       "                                           precision               0.964   \n",
       "                                           recall                  0.964   \n",
       "                                           f1_weighted             0.964   \n",
       "                                           roc_auc                 0.996   \n",
       "Support Vector Machine 0.024               accuracy                0.928   \n",
       "                                           balanced_accuracy       0.910   \n",
       "                                           precision               0.928   \n",
       "                                           recall                  0.928   \n",
       "                                           f1_weighted             0.928   \n",
       "                                           roc_auc                 0.977   \n",
       "\n",
       "                                                              Test data  \n",
       "Classifier             Classification Time Metric                        \n",
       "Random Forest          0.123               accuracy               0.893  \n",
       "                                           balanced_accuracy      0.865  \n",
       "                                           precision              0.895  \n",
       "                                           recall                 0.893  \n",
       "                                           f1_weighted            0.890  \n",
       "                                           roc_auc                0.965  \n",
       "Decision Tree          0.041               accuracy               0.810  \n",
       "                                           balanced_accuracy      0.741  \n",
       "                                           precision              0.836  \n",
       "                                           recall                 0.810  \n",
       "                                           f1_weighted            0.791  \n",
       "                                           roc_auc                0.959  \n",
       "Logistic Regression    0.041               accuracy               0.952  \n",
       "                                           balanced_accuracy      0.933  \n",
       "                                           precision              0.956  \n",
       "                                           recall                 0.952  \n",
       "                                           f1_weighted            0.952  \n",
       "                                           roc_auc                0.978  \n",
       "Support Vector Machine 0.024               accuracy               0.917  \n",
       "                                           balanced_accuracy      0.898  \n",
       "                                           precision              0.917  \n",
       "                                           recall                 0.917  \n",
       "                                           f1_weighted            0.916  \n",
       "                                           roc_auc                0.977  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.concat([pred_rf, pred_dt, pred_lg, pred_svm])\n",
    "prediction_df_report = prediction_df.set_index([\"Classifier\", \"Classification Time\", \"Metric\"])\n",
    "prediction_df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
