{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ageatscreening</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>MMSE0m</th>\n",
       "      <th>HipsASMbaseline</th>\n",
       "      <th>HipsContrastbaseline</th>\n",
       "      <th>HipsCorelationbaseline</th>\n",
       "      <th>HipsVariancebaseline</th>\n",
       "      <th>HipsSumAveragebaseline</th>\n",
       "      <th>...</th>\n",
       "      <th>ERCsContrastbaseline</th>\n",
       "      <th>ERCsCorelationbaseline</th>\n",
       "      <th>ERCsVariancebaseline</th>\n",
       "      <th>ERCsSumAveragebaseline</th>\n",
       "      <th>ERCsSumVariancebaseline</th>\n",
       "      <th>ERCsEntropybaseline</th>\n",
       "      <th>ERCsClusterShadebaseline</th>\n",
       "      <th>ERCs_thicknessbaseline</th>\n",
       "      <th>ERCsVolumebaseline</th>\n",
       "      <th>HipposcampusVolumebaseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>81.3479</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.27</td>\n",
       "      <td>0.63</td>\n",
       "      <td>218.30</td>\n",
       "      <td>28.37</td>\n",
       "      <td>...</td>\n",
       "      <td>253.10</td>\n",
       "      <td>0.40</td>\n",
       "      <td>208.65</td>\n",
       "      <td>23.39</td>\n",
       "      <td>581.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2568.19</td>\n",
       "      <td>2.31</td>\n",
       "      <td>1176.0</td>\n",
       "      <td>3047.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>67.6904</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>147.64</td>\n",
       "      <td>0.55</td>\n",
       "      <td>173.64</td>\n",
       "      <td>44.72</td>\n",
       "      <td>...</td>\n",
       "      <td>220.88</td>\n",
       "      <td>0.48</td>\n",
       "      <td>215.70</td>\n",
       "      <td>33.74</td>\n",
       "      <td>641.90</td>\n",
       "      <td>3.33</td>\n",
       "      <td>4113.01</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1942.0</td>\n",
       "      <td>3449.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73.8027</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>199.66</td>\n",
       "      <td>0.55</td>\n",
       "      <td>222.27</td>\n",
       "      <td>41.18</td>\n",
       "      <td>...</td>\n",
       "      <td>220.37</td>\n",
       "      <td>0.54</td>\n",
       "      <td>232.18</td>\n",
       "      <td>29.18</td>\n",
       "      <td>708.36</td>\n",
       "      <td>2.87</td>\n",
       "      <td>-1388.41</td>\n",
       "      <td>3.18</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>3441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>84.5945</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>184.21</td>\n",
       "      <td>0.53</td>\n",
       "      <td>201.55</td>\n",
       "      <td>43.04</td>\n",
       "      <td>...</td>\n",
       "      <td>198.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>220.48</td>\n",
       "      <td>26.68</td>\n",
       "      <td>683.50</td>\n",
       "      <td>2.77</td>\n",
       "      <td>-2506.55</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>2875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>73.9726</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>233.02</td>\n",
       "      <td>0.48</td>\n",
       "      <td>229.88</td>\n",
       "      <td>39.46</td>\n",
       "      <td>...</td>\n",
       "      <td>196.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>210.63</td>\n",
       "      <td>26.60</td>\n",
       "      <td>645.95</td>\n",
       "      <td>2.72</td>\n",
       "      <td>-1164.02</td>\n",
       "      <td>2.64</td>\n",
       "      <td>1397.0</td>\n",
       "      <td>2700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RID  Gender  Ageatscreening  Diagnosis  MMSE0m  HipsASMbaseline  \\\n",
       "0    3       0         81.3479          3    20.0              NaN   \n",
       "1    4       0         67.6904          1    27.0             0.06   \n",
       "2    5       0         73.8027          0    29.0             0.10   \n",
       "3    8       1         84.5945          0    28.0             0.08   \n",
       "4   10       1         73.9726          3    24.0             0.11   \n",
       "\n",
       "   HipsContrastbaseline  HipsCorelationbaseline  HipsVariancebaseline  \\\n",
       "0                158.27                    0.63                218.30   \n",
       "1                147.64                    0.55                173.64   \n",
       "2                199.66                    0.55                222.27   \n",
       "3                184.21                    0.53                201.55   \n",
       "4                233.02                    0.48                229.88   \n",
       "\n",
       "   HipsSumAveragebaseline  ...  ERCsContrastbaseline  ERCsCorelationbaseline  \\\n",
       "0                   28.37  ...                253.10                    0.40   \n",
       "1                   44.72  ...                220.88                    0.48   \n",
       "2                   41.18  ...                220.37                    0.54   \n",
       "3                   43.04  ...                198.42                    0.54   \n",
       "4                   39.46  ...                196.55                    0.53   \n",
       "\n",
       "   ERCsVariancebaseline  ERCsSumAveragebaseline  ERCsSumVariancebaseline  \\\n",
       "0                208.65                   23.39                   581.50   \n",
       "1                215.70                   33.74                   641.90   \n",
       "2                232.18                   29.18                   708.36   \n",
       "3                220.48                   26.68                   683.50   \n",
       "4                210.63                   26.60                   645.95   \n",
       "\n",
       "   ERCsEntropybaseline  ERCsClusterShadebaseline  ERCs_thicknessbaseline  \\\n",
       "0                  NaN                  -2568.19                    2.31   \n",
       "1                 3.33                   4113.01                    2.76   \n",
       "2                 2.87                  -1388.41                    3.18   \n",
       "3                 2.77                  -2506.55                    2.68   \n",
       "4                 2.72                  -1164.02                    2.64   \n",
       "\n",
       "   ERCsVolumebaseline  HipposcampusVolumebaseline  \n",
       "0              1176.0                      3047.0  \n",
       "1              1942.0                      3449.0  \n",
       "2              2044.0                      3441.0  \n",
       "3              1959.0                      2875.0  \n",
       "4              1397.0                      2700.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "\n",
    "# Import dataset\n",
    "dataset = pd.read_csv(\"C:/Users/steve/Desktop/Notebooks/Thesis-Project/Datasets/Raw/ADNI(Rawdata).csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group one\n",
    "group_one = dataset[dataset[\"Diagnosis\"] == 0]\n",
    "group_two = dataset[dataset[\"Diagnosis\"] == 3]\n",
    "\n",
    "combined_groups_one = pd.concat([group_one, group_two], ignore_index = True)\n",
    "combined_groups_one[\"Diagnosis\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is our target imbalanced for group one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diagnosis\n",
       "0    59.876543\n",
       "3    40.123457\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check percentage of each class\n",
    "combined_groups_one[\"Diagnosis\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as much!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((226, 22), (98, 22))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's separate into training and testing set\n",
    "combined_groups_one.drop(labels = \"RID\", axis = 1, inplace = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    combined_groups_one.drop(\"Diagnosis\", axis=1),  \n",
    "    combined_groups_one[\"Diagnosis\"],  \n",
    "    test_size=0.3,  \n",
    "    random_state=0,  \n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"imputer\", MeanMedianImputer(\n",
    "        imputation_method=\"mean\", \n",
    "        variables=[\n",
    "            'MMSE0m', 'HipsASMbaseline', 'HipsContrastbaseline',\n",
    "            'HipsCorelationbaseline', 'HipsVariancebaseline',\n",
    "            'HipsSumAveragebaseline', 'HipsSumVariancebaseline',\n",
    "            'HipsEntropybaseline', 'HipsClusterShadebaseline', \n",
    "            'ERCsASMbaseline', 'ERCsContrastbaseline', \n",
    "            'ERCsCorelationbaseline', 'ERCsVariancebaseline', \n",
    "            'ERCsSumAveragebaseline', 'ERCsSumVariancebaseline',\n",
    "            'ERCsEntropybaseline', 'ERCsClusterShadebaseline', \n",
    "            'ERCs_thicknessbaseline', 'ERCsVolumebaseline', \n",
    "            'HipposcampusVolumebaseline'\n",
    "        ]\n",
    "    )),\n",
    "    (\"scaler\", StandardScaler().set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train)\n",
    "\n",
    "# let's transform the data with the pipeline\n",
    "X_train_scaled = pipe.transform(X_train)\n",
    "X_test_scaled = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "lg = LogisticRegression(multi_class = \"auto\", solver = \"lbfgs\", max_iter = 1000, random_state = 42)\n",
    "\n",
    "svm = SVC(kernel ='rbf', decision_function_shape ='ovr', probability = True, random_state = 42)\n",
    "\n",
    "dt = decision_tree_model = DecisionTreeClassifier(criterion ='gini', max_depth = 5, min_samples_split = 10,\n",
    "                                                  min_samples_leaf = 5, max_features = 'sqrt', random_state = 42)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 100, criterion = 'gini', max_depth = 5, min_samples_split = 10, \n",
    "                            min_samples_leaf = 5, max_features = 'sqrt', bootstrap = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "# Define metrics to evaluate\n",
    "scoring_metrics = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average = 'weighted', zero_division=0),\n",
    "    'recall': make_scorer(recall_score, average = 'weighted', zero_division=0),\n",
    "    'f1': make_scorer(f1_score, average = 'weighted', zero_division=0),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "models  = {\"Logistic Regression\": lg, \n",
    "           \"Support Vector Machine\": svm, \n",
    "           \"Decision Tree\": dt, \n",
    "           \"Random Forest\": rf\n",
    "}\n",
    "\n",
    "model_data_mapping = {\n",
    "    'Logistic Regression': X_train_scaled,\n",
    "    'Support Vector Machine': X_train_scaled,\n",
    "    'Decision Tree': X_train,\n",
    "    'Random Forest': X_train\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Logistic Regression\n",
      "Mean train accuracy: 0.9845058317986494 ± 0.00544344899788108\n",
      "Mean test accuracy: 0.9733333333333334 ± 0.025915341754867992\n",
      "Mean train precision: 0.9845900278069568 ± 0.005512728998822873\n",
      "Mean test precision: 0.9742192118226601 ± 0.025498790619537207\n",
      "Mean train recall: 0.9845058317986494 ± 0.00544344899788108\n",
      "Mean test recall: 0.9733333333333334 ± 0.025915341754867992\n",
      "Mean train f1: 0.984498377809512 ± 0.005437367330516009\n",
      "Mean test f1: 0.9731793747411223 ± 0.02610560531948763\n",
      "Mean train roc_auc: 0.9834886525597619 ± 0.005174403938045408\n",
      "Mean test roc_auc: 0.970291395910591 ± 0.030353995791676323\n",
      "------------------------------------------------------\n",
      "Support Vector Machine\n",
      "Mean train accuracy: 0.9822958870472682 ± 0.004160885404953817\n",
      "Mean test accuracy: 0.9556521739130435 ± 0.0344893704615623\n",
      "Mean train precision: 0.9828497876300352 ± 0.003930861218971975\n",
      "Mean test precision: 0.9604295544468862 ± 0.027952734104091628\n",
      "Mean train recall: 0.9822958870472682 ± 0.004160885404953817\n",
      "Mean test recall: 0.9556521739130435 ± 0.0344893704615623\n",
      "Mean train f1: 0.9822357306164304 ± 0.004191135984438851\n",
      "Mean test f1: 0.9548258224200763 ± 0.03586660941819146\n",
      "Mean train roc_auc: 0.9790572999433758 ± 0.0052679493106334565\n",
      "Mean test roc_auc: 0.948918251511131 ± 0.04282972790961775\n",
      "------------------------------------------------------\n",
      "Decision Tree\n",
      "Mean train accuracy: 0.9125782688766113 ± 0.024211785741651188\n",
      "Mean test accuracy: 0.8315942028985507 ± 0.03410176373867557\n",
      "Mean train precision: 0.913093441888748 ± 0.024249901217482342\n",
      "Mean test precision: 0.8392970124968905 ± 0.03141996492698017\n",
      "Mean train recall: 0.9125782688766113 ± 0.024211785741651188\n",
      "Mean test recall: 0.8315942028985507 ± 0.03410176373867557\n",
      "Mean train f1: 0.9126157396830781 ± 0.024217149270825043\n",
      "Mean test f1: 0.8315911938073182 ± 0.032925780099693956\n",
      "Mean train roc_auc: 0.911095796250301 ± 0.02588449925959832\n",
      "Mean test roc_auc: 0.8283954822267516 ± 0.03263171562134068\n",
      "------------------------------------------------------\n",
      "Random Forest\n",
      "Mean train accuracy: 0.9922529158993247 ± 0.004429156100040546\n",
      "Mean test accuracy: 0.9555555555555555 ± 0.028109134757052262\n",
      "Mean train precision: 0.992266728054021 ± 0.004436166612651143\n",
      "Mean test precision: 0.9588615984405457 ± 0.024514580202240625\n",
      "Mean train recall: 0.9922529158993247 ± 0.004429156100040546\n",
      "Mean test recall: 0.9555555555555555 ± 0.028109134757052262\n",
      "Mean train f1: 0.9922536690483866 ± 0.004429534214409422\n",
      "Mean test f1: 0.9552270290832382 ± 0.028764763494592015\n",
      "Mean train roc_auc: 0.992184313507843 ± 0.004647533155838807\n",
      "Mean test roc_auc: 0.9532414180246999 ± 0.03386105817711435\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "\n",
    "    X_train_to_use = model_data_mapping[model_name]\n",
    "    \n",
    "    results = cross_validate(model, \n",
    "                             X_train_to_use, \n",
    "                             y_train, \n",
    "                             scoring = scoring_metrics,\n",
    "                             return_train_score = True,\n",
    "                             cv = kf)\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(model_name)\n",
    "    for metric in scoring_metrics.keys():\n",
    "            print(f'Mean train {metric}:', np.mean(results[f'train_{metric}']), '±', np.std(results[f'train_{metric}']))\n",
    "            print(f'Mean test {metric}:', np.mean(results[f'test_{metric}']), '±', np.std(results[f'test_{metric}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
