{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Now that have covered the EDA phase, lets move to some simple feature engineering tasks prior to modeling.\n",
    "\n",
    "A few things to note:\n",
    "\n",
    "* It is good practice to split the data prior to augmenting it\n",
    "* Ill drop the RID column for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "\n",
    "# Import dataset\n",
    "X_train = pd.read_csv(\"C:/Users/steve/Desktop/Notebooks/Thesis-Project/Datasets/processed/X_train_processed.csv\")\n",
    "X_test = pd.read_csv(\"C:/Users/steve/Desktop/Notebooks/Thesis-Project/Datasets/processed/X_test_processed.csv\")\n",
    "y_train = pd.read_csv(\"C:/Users/steve/Desktop/Notebooks/Thesis-Project/Datasets/processed/y_train_processed.csv\")\n",
    "y_test = pd.read_csv(\"C:/Users/steve/Desktop/Notebooks/Thesis-Project/Datasets/processed/y_test_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((425, 22), (183, 22))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "# let's transform the data \n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)\n",
    "\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline: Data imputation & feature scaling\n",
    "\n",
    "Lets extract all columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MMSE0m', 'HipsASMbaseline', 'HipsContrastbaseline',\n",
       "       'HipsCorelationbaseline', 'HipsVariancebaseline',\n",
       "       'HipsSumAveragebaseline', 'HipsSumVariancebaseline',\n",
       "       'HipsEntropybaseline', 'HipsClusterShadebaseline', 'ERCsASMbaseline',\n",
       "       'ERCsContrastbaseline', 'ERCsCorelationbaseline',\n",
       "       'ERCsVariancebaseline', 'ERCsSumAveragebaseline',\n",
       "       'ERCsSumVariancebaseline', 'ERCsEntropybaseline',\n",
       "       'ERCsClusterShadebaseline', 'ERCs_thicknessbaseline',\n",
       "       'ERCsVolumebaseline', 'HipposcampusVolumebaseline'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_columns = dataset.columns[dataset.isnull().sum() > 0]\n",
    "na_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"imputer\", MeanMedianImputer(\n",
    "        imputation_method=\"mean\", \n",
    "        variables=[\n",
    "            'MMSE0m', 'HipsASMbaseline', 'HipsContrastbaseline',\n",
    "            'HipsCorelationbaseline', 'HipsVariancebaseline',\n",
    "            'HipsSumAveragebaseline', 'HipsSumVariancebaseline',\n",
    "            'HipsEntropybaseline', 'HipsClusterShadebaseline', \n",
    "            'ERCsASMbaseline', 'ERCsContrastbaseline', \n",
    "            'ERCsCorelationbaseline', 'ERCsVariancebaseline', \n",
    "            'ERCsSumAveragebaseline', 'ERCsSumVariancebaseline',\n",
    "            'ERCsEntropybaseline', 'ERCsClusterShadebaseline', \n",
    "            'ERCs_thicknessbaseline', 'ERCsVolumebaseline', \n",
    "            'HipposcampusVolumebaseline'\n",
    "        ]\n",
    "    )),\n",
    "    (\"scaler\", StandardScaler().set_output(transform=\"pandas\")),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train)\n",
    "\n",
    "# let's transform the data with the pipeline\n",
    "X_train_scaled = pipe.transform(X_train)\n",
    "X_test_scaled = pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "* Typically, after imputing the dataset, we analyze and visualize the data to assess whether it has been significantly affected. However, for the sake of simplicity, we will temporarily skip this step.\n",
    "* A split analysis will be conducted after the first iteration.\n",
    "* Additionally, no feature selection will be performed until we complete the first iteration.\n",
    "* Variables have not been dropped.\n",
    "* Hyperparameter optimization has not been performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "We will experiment with various models that were previously mentioned in paper. \n",
    "\n",
    "* Logistic regression\n",
    "* Support vector machine\n",
    "* Decision tree\n",
    "* Random forest\n",
    "\n",
    "I will only focus on these 4 models for now. Though i would love to check how a simple ANN would work here. I'll try that afterwards.\n",
    "\n",
    "Documentation on sklearn for any of the below models\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "lg = LogisticRegression(multi_class = \"multinomial\", solver = \"lbfgs\", max_iter = 1000, random_state = 42)\n",
    "\n",
    "svm = SVC(kernel ='rbf', decision_function_shape ='ovo', probability = True, random_state = 42)\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion ='gini', max_depth = 5, min_samples_split = 10, \n",
    "                            min_samples_leaf = 5, max_features = 'sqrt', random_state = 42)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 100, criterion = 'gini', max_depth = 5, min_samples_split = 10, \n",
    "                            min_samples_leaf = 5, max_features = 'sqrt', bootstrap = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, it was stated that they performed 5 KFolds, so we will replicate their approach. \n",
    "\n",
    "ROC AUC along with other mentioned metrics will be covered here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "# Define metrics to evaluate\n",
    "scoring_metrics = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, average = 'weighted', zero_division=0),\n",
    "    'recall': make_scorer(recall_score, average = 'weighted', zero_division=0),\n",
    "    'f1': make_scorer(f1_score, average = 'weighted', zero_division=0),\n",
    "    'roc_auc': make_scorer(roc_auc_score, multi_class='ovr', response_method = \"predict_proba\")\n",
    "}\n",
    "\n",
    "models  = {\"Logistic Regression\": lg, \n",
    "           \"Support Vector Machine\": svm, \n",
    "           \"Decision Tree\": dt, \n",
    "           \"Random Forest\": rf\n",
    "}\n",
    "\n",
    "model_data_mapping = {\n",
    "    'Logistic Regression': X_train_scaled,\n",
    "    'Support Vector Machine': X_train_scaled,\n",
    "    'Decision Tree': X_train,\n",
    "    'Random Forest': X_train\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Logistic Regression\n",
      "Mean train accuracy: 0.7176470588235294 ± 0.010685824779167581\n",
      "Mean test accuracy: 0.628235294117647 ± 0.021820278812931068\n",
      "Mean train precision: 0.7137715549459933 ± 0.009994613394817947\n",
      "Mean test precision: 0.6346294513584386 ± 0.016375364642513202\n",
      "Mean train recall: 0.7176470588235294 ± 0.010685824779167581\n",
      "Mean test recall: 0.628235294117647 ± 0.021820278812931068\n",
      "Mean train f1: 0.7141321948311611 ± 0.01008676011818872\n",
      "Mean test f1: 0.6264786751157274 ± 0.018573953162226077\n",
      "Mean train roc_auc: 0.9092337235320909 ± 0.005358305500420103\n",
      "Mean test roc_auc: 0.8598573511351006 ± 0.021712265716621503\n",
      "------------------------------------------------------\n",
      "Support Vector Machine\n",
      "Mean train accuracy: 0.8023529411764706 ± 0.005060191333554468\n",
      "Mean test accuracy: 0.5999999999999999 ± 0.034899757586332535\n",
      "Mean train precision: 0.8076762897810934 ± 0.004279107619041377\n",
      "Mean test precision: 0.5951572225624752 ± 0.06058994372992349\n",
      "Mean train recall: 0.8023529411764706 ± 0.005060191333554468\n",
      "Mean test recall: 0.5999999999999999 ± 0.034899757586332535\n",
      "Mean train f1: 0.7902525236346591 ± 0.010861552429417795\n",
      "Mean test f1: 0.5822790396514332 ± 0.03686349174882935\n",
      "Mean train roc_auc: 0.961066882246229 ± 0.002089761767459735\n",
      "Mean test roc_auc: 0.8334618581934207 ± 0.01947680760974415\n",
      "------------------------------------------------------\n",
      "Decision Tree\n",
      "Mean train accuracy: 0.6611764705882353 ± 0.015607646072260716\n",
      "Mean test accuracy: 0.48470588235294115 ± 0.03965246952082993\n",
      "Mean train precision: 0.6796646938094781 ± 0.02293938320519404\n",
      "Mean test precision: 0.5226249600578503 ± 0.0779000047738367\n",
      "Mean train recall: 0.6611764705882353 ± 0.015607646072260716\n",
      "Mean test recall: 0.48470588235294115 ± 0.03965246952082993\n",
      "Mean train f1: 0.6570135443289133 ± 0.02069161904344594\n",
      "Mean test f1: 0.4885023003135574 ± 0.04736948595444704\n",
      "Mean train roc_auc: 0.8739298010448676 ± 0.011918136463410983\n",
      "Mean test roc_auc: 0.6833152973377563 ± 0.04786030153999176\n",
      "------------------------------------------------------\n",
      "Random Forest\n",
      "Mean train accuracy: 0.8288235294117646 ± 0.007979211744853274\n",
      "Mean test accuracy: 0.6329411764705882 ± 0.02919923210821376\n",
      "Mean train precision: 0.8449432677220934 ± 0.005132214027408043\n",
      "Mean test precision: 0.6291677537030343 ± 0.04999119327336689\n",
      "Mean train recall: 0.8288235294117646 ± 0.007979211744853274\n",
      "Mean test recall: 0.6329411764705882 ± 0.02919923210821376\n",
      "Mean train f1: 0.8178129408867527 ± 0.012721745820971941\n",
      "Mean test f1: 0.6014549066181137 ± 0.0322475963166305\n",
      "Mean train roc_auc: 0.9784966965143799 ± 0.0019831194312036346\n",
      "Mean test roc_auc: 0.8467384070128336 ± 0.011805596191024063\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "\n",
    "    X_train_to_use = model_data_mapping[model_name]\n",
    "    \n",
    "    results = cross_validate(model, \n",
    "                             X_train_to_use, \n",
    "                             y_train, \n",
    "                             scoring = scoring_metrics,\n",
    "                             return_train_score = True,\n",
    "                             cv = kf)\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(model_name)\n",
    "    for metric in scoring_metrics.keys():\n",
    "            print(f'Mean train {metric}:', np.mean(results[f'train_{metric}']), '±', np.std(results[f'train_{metric}']))\n",
    "            print(f'Mean test {metric}:', np.mean(results[f'test_{metric}']), '±', np.std(results[f'test_{metric}']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that based on the accuracy metric only, Random Forest can be considered as the best model with a mean test accuracy of 0.6329.\n",
    "While the worst Model would be Decision Tree, with a mean test accuracy of 0.4847."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
